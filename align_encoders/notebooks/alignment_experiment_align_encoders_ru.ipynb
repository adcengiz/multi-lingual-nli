{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 1,
   "metadata": {},
   "outputs": [],
   "source": [
    "import pickle\n",
    "import random\n",
    "import random\n",
    "import spacy\n",
    "import csv\n",
    "import sys\n",
    "import errno\n",
    "import glob\n",
    "import string\n",
    "import io\n",
    "import os\n",
    "import re\n",
    "import time\n",
    "import functools\n",
    "import numpy as np\n",
    "import pandas as pd\n",
    "from setuptools import setup\n",
    "from collections import Counter\n",
    "from collections import defaultdict\n",
    "from argparse import ArgumentParser\n",
    "\n",
    "import torch\n",
    "import torch.nn as nn\n",
    "import torch.optim as optim\n",
    "from torch.optim import lr_scheduler\n",
    "from torch.utils.data import Dataset\n",
    "import torch.nn.functional as F\n",
    "from torch.autograd import Variable\n",
    "\n",
    "import matplotlib.pyplot as plt\n",
    "%matplotlib inline"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "metadata": {},
   "outputs": [],
   "source": [
    "PAD_IDX = 0\n",
    "UNK_IDX = 1\n",
    "label_dict = {\"entailment\":0, \"neutral\":1, \"contradiction\":2}"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "metadata": {},
   "outputs": [],
   "source": [
    "no_cuda = False\n",
    "cuda = not no_cuda and torch.cuda.is_available()\n",
    "seed = 1\n",
    "device = torch.device(\"cuda\" if cuda else \"cpu\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "metadata": {},
   "outputs": [],
   "source": [
    "opus_path = \"/scratch/adc563/nlu_project/data/opus\"\n",
    "europarl_path = \"/scratch/adc563/nlu_project/data/europarl\"\n",
    "un_path = \"/scratch/adc563/nlu_project/data/un_parallel_corpora\""
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 10,
   "metadata": {},
   "outputs": [],
   "source": [
    "def read_xnli(lang):\n",
    "    fname = \"/scratch/adc563/nlu_project/data/XNLI/xnli.{}.jsonl\"\n",
    "    xnli_dev = pd.read_json(fname.format(\"dev\"), lines=True)\n",
    "    xnli_test = pd.read_json(fname.format(\"test\"), lines=True)\n",
    "    if lang == \"all\":\n",
    "        dev_data = xnli_dev\n",
    "        test_data = xnli_test\n",
    "    else:\n",
    "        dev_data = xnli_dev[xnli_dev[\"language\"]==lang]\n",
    "        test_data = xnli_test[xnli_test[\"language\"]==lang]\n",
    "    return dev_data, test_data\n",
    "\n",
    "def load_aligned_vectors(lang):\n",
    "    f = \"/scratch/adc563/nlu_project/data/aligned_embeddings/wiki.{}.align.vec\".format(lang)\n",
    "    fin = io.open(f, \"r\", encoding=\"utf-8\", newline=\"\\n\", errors=\"ignore\")\n",
    "    n, d = map(int, fin.readline().split())\n",
    "    data = {}\n",
    "    for line in fin:\n",
    "        tokens = line.rstrip().split(\" \")\n",
    "        data[tokens[0]] = [*map(float, tokens[1:])]\n",
    "    return data\n",
    "\n",
    "def load_multilingual_vectors(lang):\n",
    "    f = \"/scratch/adc563/nlu_project/data/multi_lingual_embeddings/cc.{}.300.vec\".format(lang)\n",
    "    fin = io.open(f, \"r\", encoding=\"utf-8\", newline=\"\\n\", errors=\"ignore\")\n",
    "    n, d = map(int, fin.readline().split())\n",
    "    data = {}\n",
    "    for line in fin:\n",
    "        tokens = line.rstrip().split(\" \")\n",
    "        data[tokens[0]] = [*map(float, tokens[1:])]\n",
    "    return data\n",
    "\n",
    "def load_glove_vectors(lang):\n",
    "    f = \"/scratch/adc563/nlu_project/HBMP/vector_cache/glove.840B.300d.txt\".format(lang)\n",
    "    fin = io.open(f, \"r\", encoding=\"utf-8\", newline=\"\\n\", errors=\"ignore\")\n",
    "    n = map(int, fin.readline().split())\n",
    "    data = {}\n",
    "    for line in fin:\n",
    "        tokens = line.rstrip().split(\" \")\n",
    "        data[tokens[0]] = [*map(float, tokens[1:])]\n",
    "    return data\n",
    "\n",
    "def read_enli(nli_corpus = \"snli\"):\n",
    "    if nli_corpus == \"snli\":\n",
    "        path_ = \"/scratch/adc563/nlu_project/HBMP/data/snli/snli_1.0/snli_1.0\"\n",
    "        train = pd.read_json(\"{}_{}.jsonl\".format(path_,\"train\"), lines=True)\n",
    "        dev = pd.read_json(\"{}_{}.jsonl\".format(path_,\"dev\"), lines=True)\n",
    "        test = pd.read_json(\"{}_{}.jsonl\".format(path_,\"test\"), lines=True)\n",
    "        # remove - from gold label\n",
    "        train = train[train[\"gold_label\"] != \"-\"]\n",
    "        dev = dev[dev[\"gold_label\"] != \"-\"]\n",
    "        test = test[test[\"gold_label\"] != \"-\"]\n",
    "    elif nli_corpus == \"multinli\":\n",
    "        path_ = \"/scratch/adc563/nlu_project/HBMP/data/multinli/multinli_1.0/multinli_1.0\"\n",
    "        train = pd.read_json(\"{}_{}.jsonl\".format(path_,\"train\"), lines=True)\n",
    "        dev = pd.read_json(\"{}_{}_matched.jsonl\".format(path_, \"dev\"), lines=True)\n",
    "        test = None\n",
    "        # remove - from gold label\n",
    "        train = train[train[\"gold_label\"] != \"-\"]\n",
    "        dev = dev[dev[\"gold_label\"] != \"-\"]\n",
    "    return train, dev, test\n",
    "\n",
    "def write_numeric_label(train, dev, test, nli_corpus=\"multinli\"):\n",
    "    if nli_corpus == \"multinli\":\n",
    "        for dataset in [train, dev]:\n",
    "            dataset[\"gold_label\"] = dataset[\"gold_label\"].apply(lambda x: label_dict[x])\n",
    "    elif nli_corpus == \"snli\":\n",
    "        for dataset in [train, dev, test]:\n",
    "            dataset[\"gold_label\"] = dataset[\"gold_label\"].apply(lambda x: label_dict[x])\n",
    "    elif nli_corpus == \"xnli\":\n",
    "        for dataset in [dev, test]:\n",
    "            dataset[\"gold_label\"] = dataset[\"gold_label\"].apply(lambda x: label_dict[x])\n",
    "    else:\n",
    "        raise ValueError (\"NLI corpus name should be in [multinli, snli, xnli]\")\n",
    "    return train, dev, test\n",
    "\n",
    "def tokenize_xnli(dataset, remove_punc=False, lang=\"en\"):\n",
    "    all_s1_tokens = []\n",
    "    all_s2_tokens = []\n",
    "    for s in [\"sentence1\", \"sentence2\"]:\n",
    "        punc = [*string.punctuation]\n",
    "        dataset[\"{}_tokenized\".format(s)] = dataset[\"{}\".format(s)].\\\n",
    "        apply(lambda x: \"\".join(c for c in x if c not in string.punctuation).lower().split(\" \"))\n",
    "        dataset[\"{}_tokenized\".format(s)] = dataset[\"{}_tokenized\".format(s)].\\\n",
    "        apply(lambda x: [a+\".\"+lang for a in x])\n",
    "    ext = dataset[\"sentence1_tokenized\"].apply(lambda x: all_s1_tokens.extend(x))\n",
    "    ext1 = dataset[\"sentence2_tokenized\"].apply(lambda x: all_s2_tokens.extend(x))\n",
    "    all_tokens = all_s1_tokens + all_s2_tokens\n",
    "    return dataset, all_tokens\n",
    "\n",
    "def build_vocab(all_tokens, max_vocab_size):\n",
    "    token_counter = Counter(all_tokens)\n",
    "    vocab, count = zip(*token_counter.most_common(max_vocab_size))\n",
    "    id2token = [*vocab]\n",
    "    token2id = dict(zip(vocab, range(2,2+len(vocab))))\n",
    "    id2token = ['<PAD>', '<UNK>'] + id2token\n",
    "    token2id[\"<PAD>\"] = 0\n",
    "    token2id[\"<UNK>\"] = 1\n",
    "    return token2id, id2token\n",
    "\n",
    "def build_tok2id(id2token):\n",
    "    token2id = {}\n",
    "    for i in range(len(id2token)):\n",
    "        token2id[id2token[i]] = i\n",
    "    return token2id\n",
    "\n",
    "def init_embedding_weights(vectors, token2id, id2token, embedding_size):\n",
    "    weights = np.zeros((len(id2token), embedding_size))\n",
    "    for idx in range(2, len(id2token)):\n",
    "        token = id2token[idx]\n",
    "        weights[idx] = vectors[token]\n",
    "    weights[1] = np.random.randn(embedding_size)\n",
    "    return weights"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 11,
   "metadata": {},
   "outputs": [],
   "source": [
    "class config_class:\n",
    "    def __init__(self, corpus, val_test_lang, max_sent_len, max_vocab_size, epochs, batch_size, \n",
    "                    embed_dim, hidden_dim, dropout, lr, experiment_lang):\n",
    "        self.corpus = corpus\n",
    "        self.val_test_lang = val_test_lang\n",
    "        self.max_sent_len = max_sent_len\n",
    "        self.max_vocab_size = max_vocab_size\n",
    "        self.epochs = epochs\n",
    "        self.batch_size = batch_size\n",
    "        self.embed_dim = embed_dim\n",
    "        self.hidden_dim = hidden_dim\n",
    "        self.dropout = dropout\n",
    "        self.lr = lr\n",
    "        self.experiment_lang = experiment_lang"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 12,
   "metadata": {},
   "outputs": [],
   "source": [
    "config = config_class(corpus = \"multinli\",\n",
    "             val_test_lang = \"ru\",\n",
    "             max_sent_len = 40,\n",
    "             max_vocab_size = 200000,\n",
    "             epochs = 15,\n",
    "             batch_size = 32, # decreased, because we will have contrastive batch - so x 2\n",
    "             embed_dim = 300,\n",
    "             hidden_dim = 512,\n",
    "             dropout = 0.1,\n",
    "             lr = 1e-3,\n",
    "             experiment_lang = \"ru\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 13,
   "metadata": {},
   "outputs": [],
   "source": [
    "def update_vocab_keys(src_vocab, trg_vocab):\n",
    "    for x in [*src_vocab.keys()]:\n",
    "        src_vocab[x + \".en\"] = src_vocab[x]\n",
    "        src_vocab.pop(x)\n",
    "    for y in [*trg_vocab.keys()]:\n",
    "        trg_vocab[y + \".{}\".format(config.experiment_lang)] = trg_vocab[y]\n",
    "        trg_vocab.pop(y)\n",
    "        \n",
    "    src_vocab.update(trg_vocab)\n",
    "    return src_vocab"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 14,
   "metadata": {
    "scrolled": false
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Loading vectors for EN.\n",
      "Loading vectors for RU.\n"
     ]
    }
   ],
   "source": [
    "print (\"Loading vectors for EN.\")\n",
    "aligned_src_vectors = load_glove_vectors(\"en\")\n",
    "print (\"Loading vectors for {}.\".format(config.experiment_lang.upper()))\n",
    "aligned_trg_vectors = load_aligned_vectors(config.experiment_lang)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 15,
   "metadata": {},
   "outputs": [],
   "source": [
    "id2token_src = [x+\".\"+\"en\" for x in [*aligned_src_vectors.keys()]][:config.max_vocab_size]\n",
    "id2token_trg = [x+\".\"+config.experiment_lang for x in [*aligned_trg_vectors.keys()]][:config.max_vocab_size]\n",
    "id2token_mutual = [\"<PAD>\", \"<UNK>\"] + id2token_src + id2token_trg\n",
    "vecs_mutual = update_vocab_keys(aligned_src_vectors, aligned_trg_vectors)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 16,
   "metadata": {},
   "outputs": [],
   "source": [
    "token2id_mutual = build_tok2id(id2token_mutual)\n",
    "weights_init = init_embedding_weights(vecs_mutual, token2id_mutual, id2token_mutual, 300)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 17,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "400002"
      ]
     },
     "execution_count": 17,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "len(id2token_mutual)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 18,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "(400002, 300)"
      ]
     },
     "execution_count": 18,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "weights_init.shape"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 19,
   "metadata": {},
   "outputs": [],
   "source": [
    "def read_and_tokenize_opus_data(lang=\"tr\"):\n",
    "    all_en_tokens = []\n",
    "    all_target_tokens = []\n",
    "    path_en = opus_path + \"/{}_en/OpenSubtitles.en-{}.en_00\".format(lang, lang)\n",
    "    path_target = opus_path + \"/{}_en/OpenSubtitles.en-{}.{}_00\".format(lang, lang, lang)\n",
    "    en_corpus = open(path_en, \"r\")\n",
    "    target_corpus = open(path_target, \"r\")\n",
    "    en_series = pd.Series(en_corpus.read().split(\"\\n\"))\n",
    "    target_series = pd.Series(target_corpus.read().split(\"\\n\"))\n",
    "    dataset = pd.DataFrame({\"en\":en_series, lang:target_series})\n",
    "    for i in [\"en\", lang]:\n",
    "        dataset[\"{}_tokenized\".format(i)] = dataset[i].apply(lambda x: \"\".join(c for c in x if c not in string.punctuation).lower().split(\" \"))\n",
    "        dataset[\"{}_tokenized\".format(i)] = dataset[\"{}_tokenized\".format(i)].\\\n",
    "        apply(lambda x:[a+\".{}\".format(i) for a in x])\n",
    "    dataset[\"en_tokenized\"].apply(lambda x: all_en_tokens.extend(x))\n",
    "    dataset[\"{}_tokenized\".format(lang)].apply(lambda x: all_target_tokens.extend(x))\n",
    "    return dataset, all_en_tokens, all_target_tokens"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 20,
   "metadata": {},
   "outputs": [],
   "source": [
    "def read_and_tokenize_europarl_data(lang=\"de\"):\n",
    "    all_en_tokens = []\n",
    "    all_target_tokens = []\n",
    "    path_en = europarl_path + \"/{}_en/europarl-v7.{}-en.en\".format(lang, lang)\n",
    "    path_target = europarl_path + \"/{}_en/europarl-v7.{}-en.{}\".format(lang, lang, lang)\n",
    "    en_corpus = open(path_en, \"r\")\n",
    "    target_corpus = open(path_target, \"r\")\n",
    "    en_series = pd.Series(en_corpus.read().split(\"\\n\"))\n",
    "    target_series = pd.Series(target_corpus.read().split(\"\\n\"))\n",
    "    dataset = pd.DataFrame({\"en\":en_series, lang:target_series})\n",
    "    for i in [\"en\", lang]:\n",
    "        dataset[\"{}_tokenized\".format(i)] = dataset[i].apply(lambda x: \"\".join(c for c in x if c not in string.punctuation).lower().split(\" \"))\n",
    "        dataset[\"{}_tokenized\".format(i)] = dataset[\"{}_tokenized\".format(i)].apply(lambda x:[a+\".{}\".format(i) for a in x])\n",
    "    dataset[\"en_tokenized\"].apply(lambda x: all_en_tokens.extend(x))\n",
    "    dataset[\"{}_tokenized\".format(lang)].apply(lambda x: all_target_tokens.extend(x))\n",
    "    return dataset, all_en_tokens, all_target_tokens"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 21,
   "metadata": {},
   "outputs": [],
   "source": [
    "data_en_target, all_en_tokens, all_target_tokens = read_and_tokenize_opus_data(lang=config.val_test_lang)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 22,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>en</th>\n",
       "      <th>ru</th>\n",
       "      <th>en_tokenized</th>\n",
       "      <th>ru_tokenized</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>0</th>\n",
       "      <td>Kids can get pretty much anything they want in...</td>\n",
       "      <td>Дети могут достать во дворе почти всё что угод...</td>\n",
       "      <td>[kids.en, can.en, get.en, pretty.en, much.en, ...</td>\n",
       "      <td>[дети.ru, могут.ru, достать.ru, во.ru, дворе.r...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1</th>\n",
       "      <td>'Cause everything comes with a price.</td>\n",
       "      <td>Всё имеет свою цену.</td>\n",
       "      <td>[cause.en, everything.en, comes.en, with.en, a...</td>\n",
       "      <td>[всё.ru, имеет.ru, свою.ru, цену.ru]</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2</th>\n",
       "      <td>Hey, Nick.</td>\n",
       "      <td>Эй, Ник.</td>\n",
       "      <td>[hey.en, nick.en]</td>\n",
       "      <td>[эй.ru, ник.ru]</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "</div>"
      ],
      "text/plain": [
       "                                                  en  \\\n",
       "0  Kids can get pretty much anything they want in...   \n",
       "1              'Cause everything comes with a price.   \n",
       "2                                         Hey, Nick.   \n",
       "\n",
       "                                                  ru  \\\n",
       "0  Дети могут достать во дворе почти всё что угод...   \n",
       "1                               Всё имеет свою цену.   \n",
       "2                                           Эй, Ник.   \n",
       "\n",
       "                                        en_tokenized  \\\n",
       "0  [kids.en, can.en, get.en, pretty.en, much.en, ...   \n",
       "1  [cause.en, everything.en, comes.en, with.en, a...   \n",
       "2                                  [hey.en, nick.en]   \n",
       "\n",
       "                                        ru_tokenized  \n",
       "0  [дети.ru, могут.ru, достать.ru, во.ru, дворе.r...  \n",
       "1               [всё.ru, имеет.ru, свою.ru, цену.ru]  \n",
       "2                                    [эй.ru, ник.ru]  "
      ]
     },
     "execution_count": 22,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "data_en_target.head(3)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 23,
   "metadata": {},
   "outputs": [],
   "source": [
    "def create_contrastive_dataset(dataset, trg_lang):\n",
    "    shuffle_ix_src = torch.randperm(len(dataset))\n",
    "    src_c = np.array([*dataset[\"{}_tokenized\".format(\"en\")].values])[shuffle_ix_src]\n",
    "    trg_c = dataset[\"{}_tokenized\".format(trg_lang)]\n",
    "    contrastive_df = pd.DataFrame({\"en_tokenized\": src_c, \"{}_tokenized\".format(trg_lang): trg_c})\n",
    "    return contrastive_df"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 24,
   "metadata": {},
   "outputs": [],
   "source": [
    "c_df = create_contrastive_dataset(data_en_target, config.val_test_lang)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 25,
   "metadata": {},
   "outputs": [],
   "source": [
    "c_df = c_df.iloc[torch.randperm(len(c_df))]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 26,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>en_tokenized</th>\n",
       "      <th>ru_tokenized</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>47225</th>\n",
       "      <td>[theres.en, a.en, bloody.en, great.en, bed.en,...</td>\n",
       "      <td>[приди.ru, в.ru, себя.ru, дорогая.ru, прошу.ru...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>219761</th>\n",
       "      <td>[but.en, youll.en, know.en, the.en, price.en, ...</td>\n",
       "      <td>[лошадиный.ru, моряк.ru]</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>673051</th>\n",
       "      <td>[.en, halt.en, 60.en, starboard.en, 300.en, .e...</td>\n",
       "      <td>[.ru, но.ru, я.ru, ничего.ru, не.ru, сделал.ru]</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "</div>"
      ],
      "text/plain": [
       "                                             en_tokenized  \\\n",
       "47225   [theres.en, a.en, bloody.en, great.en, bed.en,...   \n",
       "219761  [but.en, youll.en, know.en, the.en, price.en, ...   \n",
       "673051  [.en, halt.en, 60.en, starboard.en, 300.en, .e...   \n",
       "\n",
       "                                             ru_tokenized  \n",
       "47225   [приди.ru, в.ru, себя.ru, дорогая.ru, прошу.ru...  \n",
       "219761                           [лошадиный.ru, моряк.ru]  \n",
       "673051    [.ru, но.ru, я.ru, ничего.ru, не.ru, сделал.ru]  "
      ]
     },
     "execution_count": 26,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "c_df.head(3)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 27,
   "metadata": {},
   "outputs": [],
   "source": [
    "class AlignDataset(Dataset):\n",
    "    def __init__(self, data, max_sent_len, src_lang, trg_lang,\n",
    "                 token2id, id2token):\n",
    "        self.src = [*data[\"{}_tokenized\".format(src_lang)].values]\n",
    "        self.trg = [*data[\"{}_tokenized\".format(trg_lang)].values]\n",
    "        self.max_sent_len = int(max_sent_len)\n",
    "        self.token2id, self.id2token = token2id, id2token\n",
    "        \n",
    "    def __len__(self):\n",
    "        return len(self.src)\n",
    "    \n",
    "    def __getitem__(self, row):\n",
    "        src_ix, trg_ix = [], []\n",
    "        src_mask, trg_mask = [], []\n",
    "        for w in self.src[row][:self.max_sent_len]:\n",
    "            if w in self.token2id.keys():\n",
    "                src_ix.append(self.token2id[w])\n",
    "                src_mask.append(0)\n",
    "            else:\n",
    "                src_ix.append(UNK_IDX)\n",
    "                src_mask.append(1)\n",
    "        for w in self.trg[row][:self.max_sent_len]:\n",
    "            if w in self.token2id.keys():\n",
    "                trg_ix.append(self.token2id[w])\n",
    "                trg_mask.append(0)\n",
    "            else:\n",
    "                trg_ix.append(UNK_IDX)\n",
    "                trg_mask.append(1)\n",
    "        \n",
    "        src_list = [src_ix, src_mask, len(src_ix)]\n",
    "        trg_list = [trg_ix, trg_mask, len(trg_mask)]\n",
    "        return src_list + trg_list\n",
    "    \n",
    "def align_collate_func(batch, max_sent_len):\n",
    "    src_data, trg_data = [], []\n",
    "    src_mask, trg_mask = [], []\n",
    "    src_len, trg_len = [], []\n",
    "    \n",
    "    for datum in batch:\n",
    "        src_len.append(datum[2])\n",
    "        trg_len.append(datum[5])\n",
    "        src_data_padded = np.pad(np.array(datum[0]), pad_width=((0, max_sent_len-datum[2])), mode=\"constant\", constant_values=PAD_IDX)\n",
    "        src_data.append(src_data_padded)\n",
    "        src_mask_padded = np.pad(np.array(datum[1]), pad_width=((0, max_sent_len-datum[2])), mode=\"constant\", constant_values=PAD_IDX)\n",
    "        src_mask.append(src_mask_padded)\n",
    "        trg_data_padded = np.pad(np.array(datum[3]), pad_width=((0, max_sent_len-datum[5])), mode=\"constant\", constant_values=PAD_IDX)\n",
    "        trg_data.append(trg_data_padded)\n",
    "        trg_mask_padded = np.pad(np.array(datum[4]), pad_width=((0, max_sent_len-datum[5])), mode=\"constant\", constant_values=PAD_IDX)\n",
    "        trg_mask.append(trg_mask_padded)\n",
    "        \n",
    "    ind_dec_order = np.argsort(src_len)[::-1]\n",
    "    src_data = np.array(src_data)[ind_dec_order]\n",
    "    trg_data = np.array(trg_data)[ind_dec_order]\n",
    "    src_mask = np.array(src_mask)[ind_dec_order].reshape(len(batch), -1, 1)\n",
    "    trg_mask = np.array(trg_mask)[ind_dec_order].reshape(len(batch), -1, 1)\n",
    "    src_len = np.array(src_len)[ind_dec_order]\n",
    "    trg_len = np.array(trg_len)[ind_dec_order]\n",
    "\n",
    "    return [torch.from_numpy(src_data), torch.from_numpy(src_mask).float(), src_len,\n",
    "            torch.from_numpy(trg_data), torch.from_numpy(trg_mask).float(), trg_len]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 28,
   "metadata": {},
   "outputs": [],
   "source": [
    "# her epochta kaydet\n",
    "align_dataset = AlignDataset(data_en_target, config.max_sent_len, \"en\", config.experiment_lang,\n",
    "                             token2id_mutual, id2token_mutual)\n",
    "align_loader = torch.utils.data.DataLoader(dataset=align_dataset, batch_size=config.batch_size,\n",
    "                               collate_fn=lambda x, max_sentence_length=config.max_sent_len: align_collate_func(x, config.max_sent_len),\n",
    "                               shuffle=False)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 29,
   "metadata": {},
   "outputs": [],
   "source": [
    "c_align_dataset = AlignDataset(c_df, config.max_sent_len, \"en\", config.experiment_lang, \n",
    "                               token2id_mutual, id2token_mutual)\n",
    "c_align_loader = torch.utils.data.DataLoader(dataset=c_align_dataset, batch_size=config.batch_size,\n",
    "                               collate_fn=lambda x, max_sentence_length=config.max_sent_len: align_collate_func(x, config.max_sent_len),\n",
    "                               shuffle=False)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 30,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "tensor(30.9839)"
      ]
     },
     "execution_count": 30,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "torch.norm(torch.from_numpy(np.dot(torch.ones((3,4)), 2 * torch.ones((4,5)))))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 31,
   "metadata": {},
   "outputs": [],
   "source": [
    "def loss_align(en_rep, target_rep, en_c, target_c, lambda_reg):\n",
    "    \"\"\":param en_rep: output repr of eng encoder (batch_size, hidden_size)\n",
    "       :param target_rep: output repr of target encoder (batch_size, hidden_size)\n",
    "       :param en_c: contrastive sentence repr from eng encoder (batch_size, hidden_size)\n",
    "       :param target_c: contrastive sentence repr form target encoder (batch_size, hidden_size)\n",
    "       :param lambda_reg: regularization coef [default: 0.25]\n",
    "\n",
    "    Returns: L_align = l2norm (en_rep, target_rep) - lambda_reg( l2norm (en_c, target_rep) + l2norm (en_rep, target_c))\n",
    "    \"\"\"\n",
    "    dist = torch.norm(en_rep - target_rep, 2)\n",
    "    c_dist = torch.norm(en_c - target_rep, 2) + torch.norm(en_rep - target_c, 2)\n",
    "    L_align = dist - lambda_reg*(c_dist)\n",
    "    return L_align"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 32,
   "metadata": {},
   "outputs": [],
   "source": [
    "# def loss_align(en_rep, target_rep, en_c, target_c, lambda_reg):\n",
    "#     \"\"\":param en_rep: output repr of eng encoder (batch_size, hidden_size)\n",
    "#        :param target_rep: output repr of target encoder (batch_size, hidden_size)\n",
    "#        :param en_c: contrastive sentence repr from eng encoder (batch_size, hidden_size)\n",
    "#        :param target_c: contrastive sentence repr form target encoder (batch_size, hidden_size)\n",
    "#        :param lambda_reg: regularization coef [default: 0.25]\n",
    "\n",
    "#     Returns: L_align = l2norm (en_rep, target_rep) - lambda_reg( l2norm (en_c, target_rep) + l2norm (en_rep, target_c))\n",
    "#     \"\"\"\n",
    "# #     dist = torch.norm(en_rep - target_rep, 2)\n",
    "#     c_dist = torch.norm(en_c - target_rep, 2) + torch.norm(en_rep - target_c, 2)\n",
    "# #     L_align = dist - lambda_reg*(c_dist)\n",
    "#     return c_dist"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 33,
   "metadata": {},
   "outputs": [],
   "source": [
    "class biLSTM(nn.Module):\n",
    "    \n",
    "    def __init__(self,\n",
    "                 hidden_size,\n",
    "                 embedding_weights,\n",
    "                 percent_dropout,\n",
    "                 vocab_size,\n",
    "                 interaction_type=\"concat\",\n",
    "                 num_layers=1,\n",
    "                 input_size=300,\n",
    "                 src_trg = \"src\"):\n",
    "\n",
    "        super(biLSTM, self).__init__()\n",
    "        \n",
    "        self.num_layers, self.hidden_size = num_layers, hidden_size\n",
    "        \n",
    "        self.embed_table = torch.from_numpy(embedding_weights).float()\n",
    "        embedding = nn.Embedding.from_pretrained(self.embed_table)\n",
    "\n",
    "        self.embedding = embedding\n",
    "        self.interaction = interaction_type\n",
    "        self.dropout = percent_dropout\n",
    "        self.drop_out = nn.Dropout(self.dropout)\n",
    "        \n",
    "        self.LSTM = nn.LSTM(300, hidden_size, num_layers, batch_first=True, bidirectional=True)\n",
    "#         self.LSTM2 = nn.LSTM(300, hidden_size, num_layers, batch_first=True, bidirectional=True)\n",
    "#         self.LSTM3 = nn.LSTM(300, hidden_size, num_layers, batch_first=True, bidirectional=True)\n",
    "        \n",
    "        if self.LSTM.bidirectional:\n",
    "            self.num_directions = 2\n",
    "        else:\n",
    "            self.num_directions = 1\n",
    "            \n",
    "        self.bn = nn.BatchNorm1d(self.hidden_size * self.num_directions)\n",
    "        \n",
    "    def init_hidden(self, batch_size):\n",
    "        hidden = torch.randn(self.num_directions*self.num_layers, batch_size, self.hidden_size).to(device)\n",
    "        c_0 = torch.randn(self.num_directions*self.num_layers, batch_size, self.hidden_size).to(device)\n",
    "        return hidden, c_0\n",
    "    \n",
    "    def forward(self, sentence, mask, lengths):\n",
    "        sort_original = sorted(range(len(lengths)), key=lambda sentence: -lengths[sentence])\n",
    "        unsort_to_original = sorted(range(len(lengths)), key=lambda sentence: sort_original[sentence])\n",
    "        \n",
    "        sentence = sentence[sort_original]\n",
    "        _mask = mask[sort_original]\n",
    "        lengths = lengths[sort_original]\n",
    "        batch_size, seq_len = sentence.size()\n",
    "        self.hidden, self.c_0 = self.init_hidden(batch_size)\n",
    "        \n",
    "        # embdddings\n",
    "        embeds = self.embedding(sentence)\n",
    "        embeds = mask*embeds + (1-_mask)*embeds.clone().detach()\n",
    "        embeds = torch.nn.utils.rnn.pack_padded_sequence(embeds, lengths, batch_first=True)\n",
    "        # first lstm\n",
    "        lstm_out, (self.hidden_1, self.c_1) = self.LSTM(embeds, (self.hidden, self.c_0))\n",
    "        emb1, _ = torch.nn.utils.rnn.pad_packed_sequence(lstm_out, batch_first=True)\n",
    "        \n",
    "        emb1 = emb1.view(batch_size, -1, 2, self.hidden_size)\n",
    "        emb1 = torch.max(emb1, dim=1)[0]\n",
    "        emb1 = torch.cat([emb1[:,i,:] for i in range(self.num_directions)], dim=1)\n",
    "        emb1 = emb1[unsort_to_original]\n",
    "        \n",
    "        out = self.bn(emb1)\n",
    "        \n",
    "#         lstm_out_2, (self.hidden_2, self.c_2) = self.LSTM2(embeds, (self.hidden_1, self.c_1))\n",
    "#         lstm_out_2, _ = torch.nn.utils.rnn.pad_packed_sequence(lstm_out_2, batch_first=True)\n",
    "#         lstm_out_2 = lstm_out_2.view(batch_size, -1, 2, self.hidden_size)\n",
    "        \n",
    "#         lstm_out_2 = torch.max(lstm_out_2, dim=1)[0]\n",
    "#         lstm_out_2 = torch.cat([lstm_out_2[:,i,:] for i in range(self.num_directions)], dim=1)\n",
    "#         lstm_out_2 = lstm_out_2[unsort_to_original]\n",
    "        \n",
    "#         lstm_out_3, (self.hidden_3, self.c_3) = self.LSTM3(embeds, (self.hidden_2, self.c_2))\n",
    "#         lstm_out_3, _ = torch.nn.utils.rnn.pad_packed_sequence(lstm_out_3, batch_first=True)\n",
    "#         lstm_out_3 = lstm_out_3.view(batch_size, -1, 2, self.hidden_size)\n",
    "#         lstm_out_3 = torch.max(lstm_out_3, dim=1)[0]\n",
    "        \n",
    "#         lstm_out_3 = torch.cat([lstm_out_3[:,i,:] for i in range(self.num_directions)], dim=1)\n",
    "#         lstm_out_3 = lstm_out_3[unsort_to_original]\n",
    "#         out = torch.cat([emb1, lstm_out_2, lstm_out_3], dim=1)\n",
    "        \n",
    "        return out"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 38,
   "metadata": {},
   "outputs": [],
   "source": [
    "# src: always English\n",
    "def train(LSTM_src, LSTM_trg, loader, contrastive_loader, optimizer, epoch):\n",
    "    LSTM_src.train()\n",
    "    LSTM_trg.train()\n",
    "    total_loss = 0\n",
    "    for batch_idx, ([src_data, src_mask, src_len, trg_data, trg_mask, trg_len],\n",
    "                    [src_c, src_mc, src_len_c, trg_c, trg_mc, trg_len_c]) in \\\n",
    "        [*enumerate(zip(loader, contrastive_loader))]:\n",
    "        \n",
    "        src_data, src_mask = src_data.to(device), src_mask.to(device)\n",
    "        trg_data, trg_mask = trg_data.to(device), trg_mask.to(device)\n",
    "        src_c, src_mc = src_c.to(device), src_mc.to(device)\n",
    "        trg_c, trg_mc = trg_c.to(device), trg_mc.to(device)\n",
    "        optimizer.zero_grad()\n",
    "        src_out = LSTM_src(src_data, src_mask, src_len)\n",
    "        trg_out = LSTM_trg(trg_data, trg_mask, trg_len)\n",
    "        src_c_out = LSTM_src(src_c, src_mc, src_len_c)\n",
    "        trg_c_out = LSTM_trg(trg_c, trg_mc, trg_len_c)\n",
    "        loss = loss_align(src_out, trg_out, src_c_out, trg_c_out, 0.25)\n",
    "        loss.cuda().backward()\n",
    "        optimizer.step()\n",
    "        total_loss += loss.item() * len(src_data) / 400000\n",
    "        if (batch_idx+1) % (len(loader.dataset)//(20*config.batch_size)) == 0:\n",
    "            torch.save(LSTM_trg.state_dict(), \"LSTM_en_{}_{}_epoch_{}\".format(config.experiment_lang,\n",
    "                                                                      config.experiment_lang.upper(),\n",
    "                                                                      epoch))\n",
    "            print('Train Epoch: {} [{}/{} ({:.0f}%)]\\tLoss: {:.6f}'.format(\n",
    "                epoch, (batch_idx+1) * config.batch_size, 400000,\n",
    "                100. * (batch_idx+1) / len(loader), loss.item()), end=\"\\r\")\n",
    "            \n",
    "    optimizer.zero_grad()\n",
    "    return total_loss"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 39,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "(400002, 300)"
      ]
     },
     "execution_count": 39,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "weights_init.shape"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "scrolled": false
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Encoder src:\n",
      " biLSTM(\n",
      "  (embedding): Embedding(400002, 300)\n",
      "  (drop_out): Dropout(p=0.1)\n",
      "  (LSTM): LSTM(300, 512, batch_first=True, bidirectional=True)\n",
      "  (bn): BatchNorm1d(1024, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)\n",
      ")\n",
      "Encoder trg:\n",
      " biLSTM(\n",
      "  (embedding): Embedding(400002, 300)\n",
      "  (drop_out): Dropout(p=0.1)\n",
      "  (LSTM): LSTM(300, 512, batch_first=True, bidirectional=True)\n",
      "  (bn): BatchNorm1d(1024, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)\n",
      ")\n",
      "\n",
      "epoch = 0\n",
      "Train Epoch: 0 [2000000/400000 (100%)]\tLoss: 23.129967\n",
      "epoch = 1\n",
      "Train Epoch: 1 [2000000/400000 (100%)]\tLoss: 22.694405\n",
      "epoch = 2\n",
      "Train Epoch: 2 [600000/400000 (30%)]\tLoss: 24.345276\r"
     ]
    }
   ],
   "source": [
    "load_epoch = 3\n",
    "LSTM_src_model = biLSTM(hidden_size=config.hidden_dim, embedding_weights=weights_init ,num_layers=1, percent_dropout = config.dropout, \n",
    "             vocab_size=weights_init.shape[0], interaction_type=\"concat\", input_size=300).to(device)\n",
    "LSTM_src_model.load_state_dict(torch.load(\"best_encoder_eng_mnli_{}_{}\".format(load_epoch, \n",
    "                                                                        config.experiment_lang)))\n",
    "for param in LSTM_src_model.parameters():\n",
    "    param.requires_grad = False\n",
    "\n",
    "LSTM_trg_model = biLSTM(hidden_size=config.hidden_dim, embedding_weights=weights_init ,num_layers=1, percent_dropout = config.dropout, \n",
    "             vocab_size=weights_init.shape[0], interaction_type=\"concat\", input_size=300).to(device)\n",
    "LSTM_trg_model.load_state_dict(torch.load(\"best_encoder_eng_mnli_{}_{}\".format(load_epoch, \n",
    "                                                                        config.experiment_lang)))\n",
    "\n",
    "print (\"Encoder src:\\n\", LSTM_src_model)\n",
    "print (\"Encoder trg:\\n\", LSTM_trg_model)\n",
    "    \n",
    "for epoch in range(config.epochs):\n",
    "    print (\"\\nepoch = \"+str(epoch))\n",
    "    \n",
    "    loss_train = train(LSTM_src=LSTM_src_model, LSTM_trg=LSTM_trg_model, loader=align_loader, contrastive_loader=c_align_loader,\n",
    "                      optimizer = torch.optim.Adam([*LSTM_src_model.parameters()] + [*LSTM_trg_model.parameters()], lr=config.lr), \n",
    "                      epoch = epoch)\n",
    "\n",
    "    torch.save(LSTM_trg_model.state_dict(), \"LSTM_en_{}_{}_epoch_{}\".format(config.experiment_lang,\n",
    "                                                                      config.experiment_lang.upper(),\n",
    "                                                                      epoch))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# sum of loss_align and loss_align_cos"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.6.3"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
