{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 1,
   "metadata": {},
   "outputs": [],
   "source": [
    "import pickle\n",
    "import random\n",
    "import random\n",
    "import spacy\n",
    "import csv\n",
    "import sys\n",
    "import errno\n",
    "import glob\n",
    "import string\n",
    "import io\n",
    "import os\n",
    "import re\n",
    "import time\n",
    "import functools\n",
    "import numpy as np\n",
    "import pandas as pd\n",
    "from setuptools import setup\n",
    "from collections import Counter\n",
    "from collections import defaultdict\n",
    "from argparse import ArgumentParser\n",
    "\n",
    "import torch\n",
    "import torch.nn as nn\n",
    "import torch.optim as optim\n",
    "from torch.optim import lr_scheduler\n",
    "from torch.utils.data import Dataset\n",
    "import torch.nn.functional as F\n",
    "from torch.autograd import Variable\n",
    "\n",
    "import matplotlib.pyplot as plt\n",
    "%matplotlib inline"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "metadata": {},
   "outputs": [],
   "source": [
    "PAD_IDX = 0\n",
    "UNK_IDX = 1\n",
    "label_dict = {\"entailment\":0, \"neutral\":1, \"contradiction\":2}"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "metadata": {},
   "outputs": [],
   "source": [
    "no_cuda = False\n",
    "cuda = not no_cuda and torch.cuda.is_available()\n",
    "seed = 1\n",
    "device = torch.device(\"cuda\" if cuda else \"cpu\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "metadata": {},
   "outputs": [],
   "source": [
    "def read_xnli(lang):\n",
    "    fname = \"/scratch/adc563/nlu_project/data/XNLI/xnli.{}.jsonl\"\n",
    "    xnli_dev = pd.read_json(fname.format(\"dev\"), lines=True)\n",
    "    xnli_test = pd.read_json(fname.format(\"test\"), lines=True)\n",
    "    if lang == \"all\":\n",
    "        dev_data = xnli_dev\n",
    "        test_data = xnli_test\n",
    "    else:\n",
    "        dev_data = xnli_dev[xnli_dev[\"language\"]==lang]\n",
    "        test_data = xnli_test[xnli_test[\"language\"]==lang]\n",
    "    return dev_data, test_data\n",
    "\n",
    "def load_aligned_vectors(lang):\n",
    "    f = \"/scratch/adc563/nlu_project/data/aligned_embeddings/wiki.{}.align.vec\".format(lang)\n",
    "    fin = io.open(f, \"r\", encoding=\"utf-8\", newline=\"\\n\", errors=\"ignore\")\n",
    "    n, d = map(int, fin.readline().split())\n",
    "    data = {}\n",
    "    for line in fin:\n",
    "        tokens = line.rstrip().split(\" \")\n",
    "        data[tokens[0]] = [*map(float, tokens[1:])]\n",
    "    return data\n",
    "\n",
    "def load_multilingual_vectors(lang):\n",
    "    f = \"/scratch/adc563/nlu_project/data/multi_lingual_embeddings/cc.{}.300.vec\".format(lang)\n",
    "    fin = io.open(f, \"r\", encoding=\"utf-8\", newline=\"\\n\", errors=\"ignore\")\n",
    "    n, d = map(int, fin.readline().split())\n",
    "    data = {}\n",
    "    for line in fin:\n",
    "        tokens = line.rstrip().split(\" \")\n",
    "        data[tokens[0]] = [*map(float, tokens[1:])]\n",
    "    return data\n",
    "\n",
    "def load_glove_vectors(lang):\n",
    "    f = \"/scratch/adc563/nlu_project/HBMP/vector_cache/glove.840B.300d.txt\".format(lang)\n",
    "    fin = io.open(f, \"r\", encoding=\"utf-8\", newline=\"\\n\", errors=\"ignore\")\n",
    "    n = map(int, fin.readline().split())\n",
    "    data = {}\n",
    "    for line in fin:\n",
    "        tokens = line.rstrip().split(\" \")\n",
    "        data[tokens[0]] = [*map(float, tokens[1:])]\n",
    "    return data\n",
    "\n",
    "def read_enli(nli_corpus = \"snli\"):\n",
    "    if nli_corpus == \"snli\":\n",
    "        path_ = \"/scratch/adc563/nlu_project/HBMP/data/snli/snli_1.0/snli_1.0\"\n",
    "        train = pd.read_json(\"{}_{}.jsonl\".format(path_,\"train\"), lines=True)\n",
    "        dev = pd.read_json(\"{}_{}.jsonl\".format(path_,\"dev\"), lines=True)\n",
    "        test = pd.read_json(\"{}_{}.jsonl\".format(path_,\"test\"), lines=True)\n",
    "        # remove - from gold label\n",
    "        train = train[train[\"gold_label\"] != \"-\"]\n",
    "        dev = dev[dev[\"gold_label\"] != \"-\"]\n",
    "        test = test[test[\"gold_label\"] != \"-\"]\n",
    "    elif nli_corpus == \"multinli\":\n",
    "        path_ = \"/scratch/adc563/nlu_project/HBMP/data/multinli/multinli_1.0/multinli_1.0\"\n",
    "        train = pd.read_json(\"{}_{}.jsonl\".format(path_,\"train\"), lines=True)\n",
    "        dev = pd.read_json(\"{}_{}_matched.jsonl\".format(path_, \"dev\"), lines=True)\n",
    "        test = None\n",
    "        # remove - from gold label\n",
    "        train = train[train[\"gold_label\"] != \"-\"]\n",
    "        dev = dev[dev[\"gold_label\"] != \"-\"]\n",
    "    return train, dev, test\n",
    "\n",
    "def write_numeric_label(train, dev, test, nli_corpus=\"multinli\"):\n",
    "    if nli_corpus == \"multinli\":\n",
    "        for dataset in [train, dev]:\n",
    "            dataset[\"gold_label\"] = dataset[\"gold_label\"].apply(lambda x: label_dict[x])\n",
    "    elif nli_corpus == \"snli\":\n",
    "        for dataset in [train, dev, test]:\n",
    "            dataset[\"gold_label\"] = dataset[\"gold_label\"].apply(lambda x: label_dict[x])\n",
    "    elif nli_corpus == \"xnli\":\n",
    "        for dataset in [dev, test]:\n",
    "            dataset[\"gold_label\"] = dataset[\"gold_label\"].apply(lambda x: label_dict[x])\n",
    "    else:\n",
    "        raise ValueError (\"NLI corpus name should be in [multinli, snli, xnli]\")\n",
    "    return train, dev, test\n",
    "\n",
    "def tokenize_xnli(dataset, remove_punc=False, lang=\"en\"):\n",
    "    all_s1_tokens = []\n",
    "    all_s2_tokens = []\n",
    "    for s in [\"sentence1\", \"sentence2\"]:\n",
    "        punc = [*string.punctuation]\n",
    "        dataset[\"{}_tokenized\".format(s)] = dataset[\"{}\".format(s)].\\\n",
    "        apply(lambda x: \"\".join(c for c in x if c not in string.punctuation).split(\" \"))\n",
    "        dataset[\"{}_tokenized\".format(s)] = dataset[\"{}_tokenized\".format(s)].\\\n",
    "        apply(lambda x: [a+\".\"+lang for a in x])\n",
    "    ext = dataset[\"sentence1_tokenized\"].apply(lambda x: all_s1_tokens.extend(x))\n",
    "    ext1 = dataset[\"sentence2_tokenized\"].apply(lambda x: all_s2_tokens.extend(x))\n",
    "    all_tokens = all_s1_tokens + all_s2_tokens\n",
    "    return dataset, all_tokens\n",
    "\n",
    "def build_vocab(all_tokens, max_vocab_size):\n",
    "    token_counter = Counter(all_tokens)\n",
    "    vocab, count = zip(*token_counter.most_common(max_vocab_size))\n",
    "    id2token = [*vocab]\n",
    "    token2id = dict(zip(vocab, range(2,2+len(vocab))))\n",
    "    id2token = ['<PAD>', '<UNK>'] + id2token\n",
    "    token2id[\"<PAD>\"] = 0\n",
    "    token2id[\"<UNK>\"] = 1\n",
    "    return token2id, id2token\n",
    "\n",
    "def update_vocab_keys(src_vocab, trg_vocab):\n",
    "    for x in [*src_vocab.keys()]:\n",
    "        src_vocab[x + \".en\"] = src_vocab[x]\n",
    "        src_vocab.pop(x)\n",
    "    for y in [*trg_vocab.keys()]:\n",
    "        trg_vocab[y + \".fr\"] = trg_vocab[y]\n",
    "        trg_vocab.pop(y)\n",
    "        \n",
    "    src_vocab.update(trg_vocab)\n",
    "    return src_vocab\n",
    "\n",
    "def build_tok2id(id2token):\n",
    "    token2id = {}\n",
    "    for i in range(len(id2token)):\n",
    "        token2id[id2token[i]] = i\n",
    "    return token2id\n",
    "\n",
    "def init_embedding_weights(vectors, token2id, id2token, embedding_size):\n",
    "    weights = np.zeros((len(id2token), embedding_size))\n",
    "    for idx in range(2, len(id2token)):\n",
    "        token = id2token[idx]\n",
    "        weights[idx] = vectors[token]\n",
    "    weights[1] = np.random.randn(embedding_size)\n",
    "    return weights"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "metadata": {},
   "outputs": [],
   "source": [
    "class config_class:\n",
    "    def __init__(self, corpus, val_test_lang, max_sent_len, max_vocab_size, epochs, batch_size, \n",
    "                    embed_dim, hidden_dim, dropout, lr):\n",
    "        self.corpus = corpus\n",
    "        self.val_test_lang = val_test_lang\n",
    "        self.max_sent_len = max_sent_len\n",
    "        self.max_vocab_size = max_vocab_size\n",
    "        self.epochs = epochs\n",
    "        self.batch_size = batch_size\n",
    "        self.embed_dim = embed_dim\n",
    "        self.hidden_dim = hidden_dim\n",
    "        self.dropout = dropout\n",
    "        self.lr = lr"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "metadata": {},
   "outputs": [],
   "source": [
    "config = config_class(corpus = \"multinli\",\n",
    "             val_test_lang = \"fr\",\n",
    "             max_sent_len = 40,\n",
    "             max_vocab_size = 300000,\n",
    "             epochs = 15,\n",
    "             batch_size = 32, # decreased, because we will have contrastive batch - so x 2\n",
    "             embed_dim = 300,\n",
    "             hidden_dim = 512,\n",
    "             dropout = 0.12,\n",
    "             lr = 1e-3)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 7,
   "metadata": {},
   "outputs": [],
   "source": [
    "opus_path = \"/scratch/adc563/nlu_project/data/opus\"\n",
    "europarl_path = \"/scratch/adc563/nlu_project/data/europarl\"\n",
    "un_path = \"/scratch/adc563/nlu_project/data/un_parallel_corpora\""
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 8,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Loading vectors for EN.\n",
      "Loading vectors for FR.\n"
     ]
    }
   ],
   "source": [
    "print (\"Loading vectors for EN.\")\n",
    "aligned_src_vectors = load_glove_vectors(\"en\")\n",
    "print (\"Loading vectors for FR.\")\n",
    "aligned_trg_vectors = load_aligned_vectors(\"fr\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 9,
   "metadata": {},
   "outputs": [],
   "source": [
    "id2token_src = [x+\".\"+\"en\" for x in [*aligned_src_vectors.keys()]][:config.max_vocab_size]\n",
    "id2token_trg = [x+\".\"+\"fr\" for x in [*aligned_trg_vectors.keys()]][:config.max_vocab_size]\n",
    "id2token_mutual = [\"<PAD>\", \"<UNK>\"] + id2token_src + id2token_trg\n",
    "vecs_mutual = update_vocab_keys(aligned_src_vectors, aligned_trg_vectors)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 10,
   "metadata": {},
   "outputs": [],
   "source": [
    "token2id_mutual = build_tok2id(id2token_mutual)\n",
    "weights_init = init_embedding_weights(vecs_mutual, token2id_mutual, id2token_mutual, 300)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 11,
   "metadata": {},
   "outputs": [],
   "source": [
    "def read_and_tokenize_opus_data(lang=\"tr\"):\n",
    "    all_en_tokens = []\n",
    "    all_target_tokens = []\n",
    "    path_en = opus_path + \"/{}_en/en_data_00\".format(lang, lang)\n",
    "    path_target = opus_path + \"/{}_en/{}_data_00\".format(lang, lang)\n",
    "    en_corpus = open(path_en, \"r\")\n",
    "    target_corpus = open(path_target, \"r\")\n",
    "    en_series = pd.Series(en_corpus.read().split(\"\\n\"))\n",
    "    target_series = pd.Series(target_corpus.read().split(\"\\n\"))\n",
    "    dataset = pd.DataFrame({\"en\":en_series, lang:target_series})\n",
    "    for i in [\"en\", lang]:\n",
    "        dataset[\"{}_tokenized\".format(i)] = dataset[i].apply(lambda x: \"\".join(c for c in x if c not in string.punctuation).split(\" \"))\n",
    "        dataset[\"{}_tokenized\".format(i)] = dataset[\"{}_tokenized\".format(i)].\\\n",
    "        apply(lambda x:[a+\".{}\".format(i) for a in x])\n",
    "    dataset[\"en_tokenized\"].apply(lambda x: all_en_tokens.extend(x))\n",
    "    dataset[\"{}_tokenized\".format(lang)].apply(lambda x: all_target_tokens.extend(x))\n",
    "    return dataset, all_en_tokens, all_target_tokens"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 12,
   "metadata": {},
   "outputs": [],
   "source": [
    "def read_and_tokenize_europarl_data(lang=\"de\"):\n",
    "    all_en_tokens = []\n",
    "    all_target_tokens = []\n",
    "    path_en = europarl_path + \"/{}_en/europarl-v7.{}-en.en\".format(lang, lang)\n",
    "    path_target = europarl_path + \"/{}_en/europarl-v7.{}-en.{}\".format(lang, lang, lang)\n",
    "    en_corpus = open(path_en, \"r\")\n",
    "    target_corpus = open(path_target, \"r\")\n",
    "    en_series = pd.Series(en_corpus.read().split(\"\\n\"))\n",
    "    target_series = pd.Series(target_corpus.read().split(\"\\n\"))\n",
    "    dataset = pd.DataFrame({\"en\":en_series, lang:target_series})\n",
    "    for i in [\"en\", lang]:\n",
    "        dataset[\"{}_tokenized\".format(i)] = dataset[i].apply(lambda x: \"\".join(c for c in x if c not in string.punctuation).split(\" \"))\n",
    "        dataset[\"{}_tokenized\".format(i)] = dataset[\"{}_tokenized\".format(i)].apply(lambda x:[a+\".{}\".format(i) for a in x])\n",
    "    dataset[\"en_tokenized\"].apply(lambda x: all_en_tokens.extend(x))\n",
    "    dataset[\"{}_tokenized\".format(lang)].apply(lambda x: all_target_tokens.extend(x))\n",
    "    return dataset, all_en_tokens, all_target_tokens"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 13,
   "metadata": {},
   "outputs": [],
   "source": [
    "class biLSTM(nn.Module):\n",
    "    \n",
    "    def __init__(self,\n",
    "                 hidden_size,\n",
    "                 embedding_weights,\n",
    "                 percent_dropout,\n",
    "                 vocab_size,\n",
    "                 interaction_type=\"concat\",\n",
    "                 num_layers=1,\n",
    "                 input_size=300,\n",
    "                 src_trg = \"src\"):\n",
    "\n",
    "        super(biLSTM, self).__init__()\n",
    "        \n",
    "        self.num_layers, self.hidden_size = num_layers, hidden_size\n",
    "        \n",
    "        self.embed_table = torch.from_numpy(embedding_weights).float()\n",
    "        embedding = nn.Embedding.from_pretrained(self.embed_table)\n",
    "\n",
    "        self.embedding = embedding\n",
    "        self.interaction = interaction_type\n",
    "        self.dropout = percent_dropout\n",
    "        self.drop_out = nn.Dropout(self.dropout)\n",
    "        \n",
    "        self.LSTM = nn.LSTM(300, hidden_size, num_layers, batch_first=True, bidirectional=True)\n",
    "#         self.LSTM2 = nn.LSTM(300, hidden_size, num_layers, batch_first=True, bidirectional=True)\n",
    "#         self.LSTM3 = nn.LSTM(300, hidden_size, num_layers, batch_first=True, bidirectional=True)\n",
    "        \n",
    "        if self.LSTM.bidirectional:\n",
    "            self.num_directions = 2\n",
    "        else:\n",
    "            self.num_directions = 1\n",
    "        \n",
    "    def init_hidden(self, batch_size):\n",
    "        hidden = torch.randn(self.num_directions*self.num_layers, batch_size, self.hidden_size).to(device)\n",
    "        c_0 = torch.randn(self.num_directions*self.num_layers, batch_size, self.hidden_size).to(device)\n",
    "        return hidden, c_0\n",
    "    \n",
    "    def forward(self, sentence, mask, lengths):\n",
    "        sort_original = sorted(range(len(lengths)), key=lambda sentence: -lengths[sentence])\n",
    "        unsort_to_original = sorted(range(len(lengths)), key=lambda sentence: sort_original[sentence])\n",
    "        \n",
    "        sentence = sentence[sort_original]\n",
    "        _mask = mask[sort_original]\n",
    "        lengths = lengths[sort_original]\n",
    "        batch_size, seq_len = sentence.size()\n",
    "        self.hidden, self.c_0 = self.init_hidden(batch_size)\n",
    "        \n",
    "        # embdddings\n",
    "        embeds = self.embedding(sentence)\n",
    "        embeds = mask*embeds + (1-_mask)*embeds.clone().detach()\n",
    "        embeds = torch.nn.utils.rnn.pack_padded_sequence(embeds, lengths, batch_first=True)\n",
    "        # first lstm\n",
    "        lstm_out, (self.hidden_1, self.c_1) = self.LSTM(embeds, (self.hidden, self.c_0))\n",
    "        emb1, _ = torch.nn.utils.rnn.pad_packed_sequence(lstm_out, batch_first=True)\n",
    "        \n",
    "        emb1 = emb1.view(batch_size, -1, 2, self.hidden_size)\n",
    "        emb1 = torch.max(emb1, dim=1)[0]\n",
    "        emb1 = torch.cat([emb1[:,i,:] for i in range(self.num_directions)], dim=1)\n",
    "        emb1 = emb1[unsort_to_original]\n",
    "        \n",
    "#         lstm_out_2, (self.hidden_2, self.c_2) = self.LSTM2(embeds, (self.hidden_1, self.c_1))\n",
    "#         lstm_out_2, _ = torch.nn.utils.rnn.pad_packed_sequence(lstm_out_2, batch_first=True)\n",
    "#         lstm_out_2 = lstm_out_2.view(batch_size, -1, 2, self.hidden_size)\n",
    "        \n",
    "#         lstm_out_2 = torch.max(lstm_out_2, dim=1)[0]\n",
    "#         lstm_out_2 = torch.cat([lstm_out_2[:,i,:] for i in range(self.num_directions)], dim=1)\n",
    "#         lstm_out_2 = lstm_out_2[unsort_to_original]\n",
    "        \n",
    "#         lstm_out_3, (self.hidden_3, self.c_3) = self.LSTM3(embeds, (self.hidden_2, self.c_2))\n",
    "#         lstm_out_3, _ = torch.nn.utils.rnn.pad_packed_sequence(lstm_out_3, batch_first=True)\n",
    "#         lstm_out_3 = lstm_out_3.view(batch_size, -1, 2, self.hidden_size)\n",
    "#         lstm_out_3 = torch.max(lstm_out_3, dim=1)[0]\n",
    "        \n",
    "#         lstm_out_3 = torch.cat([lstm_out_3[:,i,:] for i in range(self.num_directions)], dim=1)\n",
    "#         lstm_out_3 = lstm_out_3[unsort_to_original]\n",
    "#         out = torch.cat([emb1, lstm_out_2, lstm_out_3], dim=1)\n",
    "        \n",
    "        return emb1"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 14,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Reading multinli data.\n",
      "Writing numeric label.\n",
      "Reading XNLI FR data.\n"
     ]
    }
   ],
   "source": [
    "# load train and preprocess\n",
    "print (\"Reading {} data.\".format(config.corpus))\n",
    "nli_train, nli_dev, nli_test = read_enli(nli_corpus=config.corpus)\n",
    "print (\"Writing numeric label.\")\n",
    "if config.corpus == \"multinli\":\n",
    "    nli_train, nli_dev, _ = write_numeric_label(nli_train, nli_dev, nli_test, nli_corpus=config.corpus)\n",
    "elif config.corpus == \"snli\":\n",
    "    nli_train, nli_dev, nli_test = write_numeric_label(nli_train, nli_dev, nli_test, nli_corpus=config.corpus)\n",
    "\n",
    "# load val and test and preprocess\n",
    "print (\"Reading XNLI {} data.\".format(config.val_test_lang.upper()))\n",
    "xnli_dev, xnli_test = read_xnli(config.val_test_lang)\n",
    "_, xnli_dev, xnli_test = write_numeric_label(None, xnli_dev, xnli_test, nli_corpus=\"xnli\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 15,
   "metadata": {},
   "outputs": [],
   "source": [
    "nli_train, all_train_tokens = tokenize_xnli(nli_train, lang=\"en\")\n",
    "# nli_dev = tokenize_enli(nli_dev)\n",
    "xnli_dev, _ = tokenize_xnli(xnli_dev, lang=config.val_test_lang)\n",
    "xnli_test, _ = tokenize_xnli(xnli_test, lang=config.val_test_lang)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": 16,
   "metadata": {},
   "outputs": [],
   "source": [
    "class NLIDataset(Dataset):\n",
    "    def __init__(self, tokenized_dataset, max_sentence_length, token2id, id2token):\n",
    "        self.sentence1, self.sentence2, self.labels = [*tokenized_dataset[\"sentence1_tokenized\"].values], \\\n",
    "                                                      [*tokenized_dataset[\"sentence2_tokenized\"].values], \\\n",
    "                                                      [*tokenized_dataset[\"gold_label\"].values]\n",
    "        self.max_sentence_length = int(max_sentence_length)\n",
    "        self.token2id, self.id2token = token2id, id2token\n",
    "        \n",
    "    def __len__(self):\n",
    "        return len(self.labels)\n",
    "    \n",
    "    def __getitem__(self, row):\n",
    "        label = self.labels[row]\n",
    "        sentence1_word_idx, sentence2_word_idx = [], []\n",
    "        sentence1_mask, sentence2_mask = [], []\n",
    "        for word in self.sentence1[row][:self.max_sentence_length]:\n",
    "            if word in self.token2id.keys():\n",
    "                sentence1_word_idx.append(self.token2id[word])\n",
    "                sentence1_mask.append(0)\n",
    "            else:\n",
    "                sentence1_word_idx.append(UNK_IDX)\n",
    "                sentence1_mask.append(1)\n",
    "        for word in self.sentence2[row][:self.max_sentence_length]:\n",
    "            if word in self.token2id.keys():\n",
    "                sentence2_word_idx.append(self.token2id[word])\n",
    "                sentence2_mask.append(0)\n",
    "            else:\n",
    "                sentence2_word_idx.append(UNK_IDX)\n",
    "                sentence2_mask.append(1)\n",
    "        sentence1_list = [sentence1_word_idx, sentence1_mask, len(sentence1_word_idx)]\n",
    "        sentence2_list = [sentence2_word_idx, sentence2_mask, len(sentence2_word_idx)]\n",
    "        \n",
    "        return sentence1_list + sentence2_list + [label]\n",
    "\n",
    "def nli_collate_func(batch, max_sent_length):\n",
    "    sentence1_data, sentence2_data = [], []\n",
    "    sentence1_mask, sentence2_mask = [], []\n",
    "    s1_lengths, s2_lengths = [], []\n",
    "    labels = []\n",
    "\n",
    "    for datum in batch:\n",
    "        s1_lengths.append(datum[2])\n",
    "        s2_lengths.append(datum[5])\n",
    "        labels.append(datum[6])\n",
    "        sentence1_data_padded = np.pad(np.array(datum[0]), pad_width=((0, config.max_sent_len-datum[2])), mode=\"constant\", constant_values=0)\n",
    "        sentence1_data.append(sentence1_data_padded)\n",
    "        sentence1_mask_padded = np.pad(np.array(datum[1]), pad_width=((0, config.max_sent_len-datum[2])), mode=\"constant\", constant_values=0)\n",
    "        sentence1_mask.append(sentence1_mask_padded)\n",
    "        sentence2_data_padded = np.pad(np.array(datum[3]), pad_width=((0, config.max_sent_len-datum[5])), mode=\"constant\", constant_values=0)\n",
    "        sentence2_data.append(sentence2_data_padded)\n",
    "        sentence2_mask_padded = np.pad(np.array(datum[4]), pad_width=((0, config.max_sent_len-datum[5])), mode=\"constant\", constant_values=0)\n",
    "        sentence2_mask.append(sentence2_mask_padded)\n",
    "        \n",
    "    ind_dec_order = np.argsort(s1_lengths)[::-1]\n",
    "    sentence1_data = np.array(sentence1_data)[ind_dec_order]\n",
    "    sentence2_data = np.array(sentence2_data)[ind_dec_order]\n",
    "    sentence1_mask = np.array(sentence1_mask)[ind_dec_order].reshape(len(batch), -1, 1)\n",
    "    sentence2_mask = np.array(sentence2_mask)[ind_dec_order].reshape(len(batch), -1, 1)\n",
    "    s1_lengths = np.array(s1_lengths)[ind_dec_order]\n",
    "    s2_lengths = np.array(s2_lengths)[ind_dec_order]\n",
    "    labels = np.array(labels)[ind_dec_order]\n",
    "    \n",
    "    s1_list = [torch.from_numpy(sentence1_data), torch.from_numpy(sentence1_mask).float(), s1_lengths]\n",
    "    s2_list = [torch.from_numpy(sentence2_data), torch.from_numpy(sentence2_mask).float(), s2_lengths]\n",
    "        \n",
    "    return [torch.from_numpy(sentence1_data), torch.from_numpy(sentence1_mask).float(), s1_lengths,\n",
    "            torch.from_numpy(sentence2_data), torch.from_numpy(sentence2_mask).float(), s2_lengths,\n",
    "            labels]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 17,
   "metadata": {},
   "outputs": [],
   "source": [
    "# train\n",
    "nli_train_dataset = NLIDataset(nli_train, max_sentence_length=config.max_sent_len, token2id=token2id_mutual, id2token=id2token_mutual)\n",
    "nli_train_loader = torch.utils.data.DataLoader(dataset=nli_train_dataset, batch_size=config.batch_size,\n",
    "                               collate_fn=lambda x, max_sentence_length=config.max_sent_len: nli_collate_func(x, config.max_sent_len),\n",
    "                               shuffle=False)\n",
    "\n",
    "# dev\n",
    "nli_dev_dataset = NLIDataset(xnli_dev, max_sentence_length=config.max_sent_len, token2id=token2id_mutual, id2token=id2token_mutual)\n",
    "nli_dev_loader = torch.utils.data.DataLoader(dataset=nli_dev_dataset, batch_size=config.batch_size,\n",
    "                               collate_fn=lambda x, max_sentence_length=config.max_sent_len: nli_collate_func(x, config.max_sent_len),\n",
    "                               shuffle=False)\n",
    "\n",
    "# test\n",
    "nli_test_dataset = NLIDataset(xnli_test, max_sentence_length=config.max_sent_len, token2id=token2id_mutual, id2token=id2token_mutual)\n",
    "nli_test_loader = torch.utils.data.DataLoader(dataset=nli_test_dataset, batch_size=config.batch_size,\n",
    "                               collate_fn=lambda x, max_sentence_length=config.max_sent_len: nli_collate_func(x, config.max_sent_len),\n",
    "                               shuffle=False)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 18,
   "metadata": {},
   "outputs": [],
   "source": [
    "class Linear_Layers(nn.Module):\n",
    "    \n",
    "    def __init__(self, hidden_size, hidden_size_2, percent_dropout,\n",
    "                 interaction_type=\"concat\", classes=3, input_size=300):\n",
    "        \n",
    "        super(Linear_Layers, self).__init__()\n",
    "        self.interaction = interaction_type\n",
    "        self.num_classes = classes\n",
    "        self.hidden_size = hidden_size\n",
    "        self.hidden_size_2 = hidden_size_2\n",
    "        self.percent_dropout = percent_dropout\n",
    "        self.num_classes = classes\n",
    "        \n",
    "        if self.interaction == \"concat\":\n",
    "            self.mlp = nn.Sequential(\n",
    "                nn.Linear(4 * self.hidden_size, self.hidden_size_2),\n",
    "                nn.ReLU(inplace=True),\n",
    "                nn.Dropout(p=self.percent_dropout),\n",
    "                nn.Linear(self.hidden_size_2, self.num_classes))\n",
    "        else:\n",
    "            self.mlp = nn.Sequential(\n",
    "                nn.Dropout(p=self.percent_dropout),\n",
    "                nn.Linear(6 * self.hidden_size, self.hidden_size_2),\n",
    "                nn.ReLU(inplace=True),\n",
    "                nn.Dropout(p=self.percent_dropout),\n",
    "                nn.Linear(self.hidden_size_2, int(self.hidden_size_2/2)),\n",
    "                nn.ReLU(inplace=True),\n",
    "                nn.Linear(int(self.hidden_size_2/2), self.num_classes))\n",
    "\n",
    "        self.init_weights()\n",
    "        \n",
    "    def init_weights(self):\n",
    "        for module in self.modules():\n",
    "            if isinstance(module, nn.Linear):\n",
    "                nn.init.xavier_normal_(module.weight)\n",
    "                nn.init.uniform_(module.bias)\n",
    "\n",
    "    def forward(self, lstm_out_1, lstm_out_2):\n",
    "        if self.interaction == \"concat\":\n",
    "            hidden = torch.cat([lstm_out_1, lstm_out_2, torch.abs(lstm_out_1 - lstm_out_2), \n",
    "                                torch.mul(lstm_out_1, lstm_out_2)], dim=1)\n",
    "        elif self.interaction == \"mul\":\n",
    "            hidden = lstm_out_1*lstm_out_2\n",
    "        elif self.interaction == \"subtract\":\n",
    "            hidden = lstm_out_1-lstm_out_2\n",
    "        hidden = hidden.view(hidden.size(0),-1) \n",
    "        out = self.mlp(hidden)\n",
    "        out = F.log_softmax(out, 1)\n",
    "        return out"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 19,
   "metadata": {},
   "outputs": [],
   "source": [
    "def test(RNN, Linear_Classifier, DataLoader, criterion):\n",
    "\n",
    "    RNN.eval()\n",
    "    Linear_Classifier.eval()\n",
    "    test_loss = 0\n",
    "    label_list = []\n",
    "    output_list = []\n",
    "    with torch.no_grad():\n",
    "        for batch_idx, (sentence1, s1_original, sentence1_lengths, \n",
    "                    sentence2, s2_original, sentence2_lengths, labels)\\\n",
    "                    in enumerate(DataLoader):\n",
    "\n",
    "            sentence1, s1_original = sentence1.to(device), s1_original.to(device),  \n",
    "            sentence2, s2_original = sentence2.to(device), s2_original.to(device),\n",
    "            labels = torch.from_numpy(labels).to(device)\n",
    "            output_s1 = RNN(sentence1, s1_original, sentence1_lengths)\n",
    "            output_s2 = RNN(sentence2, s2_original, sentence2_lengths)\n",
    "            out = Linear_Classifier(output_s1, output_s2)\n",
    "            loss = criterion(out, labels)\n",
    "            test_loss += loss.item()/len(DataLoader.dataset)\n",
    "            output_list.append(out)\n",
    "            label_list.append(labels)\n",
    "            \n",
    "    return test_loss, torch.cat(output_list, dim=0), torch.cat(label_list, dim=0)\n",
    "\n",
    "def accuracy(RNN, Linear_Classifier, DataLoader, criterion):\n",
    "    \n",
    "    _, predicted, true_labels = test(RNN = RNN,  Linear_Classifier = Linear_Classifier,\n",
    "                                     DataLoader = DataLoader, criterion = criterion)\n",
    "\n",
    "    predicted = predicted.max(1)[1]\n",
    "    return 100 * predicted.eq(true_labels.data.view_as(predicted)).float().mean().item()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 20,
   "metadata": {},
   "outputs": [],
   "source": [
    "vocab_size = config.max_vocab_size\n",
    "num_classes = 3\n",
    "num_layers = 1\n",
    "bidirectional = True\n",
    "lstm_hidden_size = 512\n",
    "classifier_hidden_size = 1024"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 21,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>annotator_labels</th>\n",
       "      <th>genre</th>\n",
       "      <th>gold_label</th>\n",
       "      <th>language</th>\n",
       "      <th>match</th>\n",
       "      <th>pairID</th>\n",
       "      <th>promptID</th>\n",
       "      <th>sentence1</th>\n",
       "      <th>sentence1_tokenized</th>\n",
       "      <th>sentence2</th>\n",
       "      <th>sentence2_tokenized</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>14940</th>\n",
       "      <td>[neutral, contradiction, neutral, neutral, neu...</td>\n",
       "      <td>facetoface</td>\n",
       "      <td>1</td>\n",
       "      <td>fr</td>\n",
       "      <td>True</td>\n",
       "      <td>1</td>\n",
       "      <td>1</td>\n",
       "      <td>Et il a dit, maman, je suis à la maison.</td>\n",
       "      <td>[Et.fr, il.fr, a.fr, dit.fr, maman.fr, je.fr, ...</td>\n",
       "      <td>Il a appelé sa mère dès que le bus scolaire l'...</td>\n",
       "      <td>[Il.fr, a.fr, appelé.fr, sa.fr, mère.fr, dès.f...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>14941</th>\n",
       "      <td>[contradiction, contradiction, contradiction, ...</td>\n",
       "      <td>facetoface</td>\n",
       "      <td>2</td>\n",
       "      <td>fr</td>\n",
       "      <td>True</td>\n",
       "      <td>2</td>\n",
       "      <td>1</td>\n",
       "      <td>Et il a dit, maman, je suis à la maison.</td>\n",
       "      <td>[Et.fr, il.fr, a.fr, dit.fr, maman.fr, je.fr, ...</td>\n",
       "      <td>Il n'a pas dit un mot.</td>\n",
       "      <td>[Il.fr, na.fr, pas.fr, dit.fr, un.fr, mot.fr]</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>14942</th>\n",
       "      <td>[entailment, entailment, neutral, entailment, ...</td>\n",
       "      <td>facetoface</td>\n",
       "      <td>0</td>\n",
       "      <td>fr</td>\n",
       "      <td>True</td>\n",
       "      <td>3</td>\n",
       "      <td>1</td>\n",
       "      <td>Et il a dit, maman, je suis à la maison.</td>\n",
       "      <td>[Et.fr, il.fr, a.fr, dit.fr, maman.fr, je.fr, ...</td>\n",
       "      <td>Il a dit à sa mère qu'il était rentré.</td>\n",
       "      <td>[Il.fr, a.fr, dit.fr, à.fr, sa.fr, mère.fr, qu...</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "</div>"
      ],
      "text/plain": [
       "                                        annotator_labels       genre  \\\n",
       "14940  [neutral, contradiction, neutral, neutral, neu...  facetoface   \n",
       "14941  [contradiction, contradiction, contradiction, ...  facetoface   \n",
       "14942  [entailment, entailment, neutral, entailment, ...  facetoface   \n",
       "\n",
       "       gold_label language match  pairID  promptID  \\\n",
       "14940           1       fr  True       1         1   \n",
       "14941           2       fr  True       2         1   \n",
       "14942           0       fr  True       3         1   \n",
       "\n",
       "                                      sentence1  \\\n",
       "14940  Et il a dit, maman, je suis à la maison.   \n",
       "14941  Et il a dit, maman, je suis à la maison.   \n",
       "14942  Et il a dit, maman, je suis à la maison.   \n",
       "\n",
       "                                     sentence1_tokenized  \\\n",
       "14940  [Et.fr, il.fr, a.fr, dit.fr, maman.fr, je.fr, ...   \n",
       "14941  [Et.fr, il.fr, a.fr, dit.fr, maman.fr, je.fr, ...   \n",
       "14942  [Et.fr, il.fr, a.fr, dit.fr, maman.fr, je.fr, ...   \n",
       "\n",
       "                                               sentence2  \\\n",
       "14940  Il a appelé sa mère dès que le bus scolaire l'...   \n",
       "14941                             Il n'a pas dit un mot.   \n",
       "14942             Il a dit à sa mère qu'il était rentré.   \n",
       "\n",
       "                                     sentence2_tokenized  \n",
       "14940  [Il.fr, a.fr, appelé.fr, sa.fr, mère.fr, dès.f...  \n",
       "14941      [Il.fr, na.fr, pas.fr, dit.fr, un.fr, mot.fr]  \n",
       "14942  [Il.fr, a.fr, dit.fr, à.fr, sa.fr, mère.fr, qu...  "
      ]
     },
     "execution_count": 21,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "xnli_dev.head(3)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 26,
   "metadata": {},
   "outputs": [],
   "source": [
    "epoch = 0\n",
    "LSTM_trg = biLSTM(hidden_size=config.hidden_dim, embedding_weights=weights_init, num_layers=1, percent_dropout = config.dropout, \n",
    "             vocab_size=weights_init.shape[0], interaction_type=\"concat\", input_size=300, src_trg=\"src\").to(device)\n",
    "\n",
    "LSTM_trg.load_state_dict(torch.load(\"LSTM_en_fr_FR_epoch_{}\".format(epoch)))\n",
    "\n",
    "linear_model = Linear_Layers(hidden_size = classifier_hidden_size, hidden_size_2 = 128,\n",
    "                             percent_dropout = 0.1, interaction_type=\"concat\", \n",
    "                             classes=3, input_size=300).to(device)\n",
    "\n",
    "linear_model.load_state_dict(torch.load(\"best_linear_eng_mnli_4\"))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 27,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "\n",
      "FR Validation Accuracy = 59.23694968223572\n"
     ]
    }
   ],
   "source": [
    "val_acc = accuracy(LSTM_trg, linear_model, nli_dev_loader, nn.NLLLoss(reduction='sum'))\n",
    "print (\"\\n{} Validation Accuracy = {}\".format(config.val_test_lang.upper(), val_acc))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 28,
   "metadata": {},
   "outputs": [],
   "source": [
    "epoch = 1\n",
    "LSTM_trg = biLSTM(hidden_size=config.hidden_dim, embedding_weights=weights_init, num_layers=1, percent_dropout = config.dropout, \n",
    "             vocab_size=weights_init.shape[0], interaction_type=\"concat\", input_size=300, src_trg=\"src\").to(device)\n",
    "\n",
    "LSTM_trg.load_state_dict(torch.load(\"LSTM_en_fr_FR_epoch_{}\".format(epoch)))\n",
    "\n",
    "linear_model = Linear_Layers(hidden_size = classifier_hidden_size, hidden_size_2 = 128,\n",
    "                             percent_dropout = 0.1, interaction_type=\"concat\", \n",
    "                             classes=3, input_size=300).to(device)\n",
    "\n",
    "linear_model.load_state_dict(torch.load(\"best_linear_eng_mnli_3\"))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 29,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "\n",
      "FR Validation Accuracy = 59.036147594451904\n"
     ]
    }
   ],
   "source": [
    "val_acc = accuracy(LSTM_trg, linear_model, nli_dev_loader, nn.NLLLoss(reduction='sum'))\n",
    "print (\"\\n{} Validation Accuracy = {}\".format(config.val_test_lang.upper(), val_acc))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 30,
   "metadata": {},
   "outputs": [],
   "source": [
    "epoch = 2\n",
    "LSTM_trg = biLSTM(hidden_size=config.hidden_dim, embedding_weights=weights_init, num_layers=1, percent_dropout = config.dropout, \n",
    "             vocab_size=weights_init.shape[0], interaction_type=\"concat\", input_size=300, src_trg=\"src\").to(device)\n",
    "\n",
    "LSTM_trg.load_state_dict(torch.load(\"LSTM_en_fr_FR_epoch_{}\".format(epoch)))\n",
    "\n",
    "linear_model = Linear_Layers(hidden_size = classifier_hidden_size, hidden_size_2 = 128,\n",
    "                             percent_dropout = 0.1, interaction_type=\"concat\", \n",
    "                             classes=3, input_size=300).to(device)\n",
    "\n",
    "linear_model.load_state_dict(torch.load(\"best_linear_eng_mnli_4\"))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 31,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "\n",
      "FR Validation Accuracy = 62.489962577819824\n"
     ]
    }
   ],
   "source": [
    "val_acc = accuracy(LSTM_trg, linear_model, nli_dev_loader, nn.NLLLoss(reduction='sum'))\n",
    "print (\"\\n{} Validation Accuracy = {}\".format(config.val_test_lang.upper(), val_acc))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 32,
   "metadata": {},
   "outputs": [],
   "source": [
    "epoch = 3\n",
    "LSTM_trg = biLSTM(hidden_size=config.hidden_dim, embedding_weights=weights_init, num_layers=1, percent_dropout = config.dropout, \n",
    "             vocab_size=weights_init.shape[0], interaction_type=\"concat\", input_size=300, src_trg=\"src\").to(device)\n",
    "\n",
    "LSTM_trg.load_state_dict(torch.load(\"LSTM_en_fr_FR_epoch_{}\".format(epoch)))\n",
    "\n",
    "linear_model = Linear_Layers(hidden_size = classifier_hidden_size, hidden_size_2 = 128,\n",
    "                             percent_dropout = 0.1, interaction_type=\"concat\", \n",
    "                             classes=3, input_size=300).to(device)\n",
    "\n",
    "linear_model.load_state_dict(torch.load(\"best_linear_eng_mnli_4\"))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 33,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "\n",
      "FR Validation Accuracy = 61.887550354003906\n"
     ]
    }
   ],
   "source": [
    "val_acc = accuracy(LSTM_trg, linear_model, nli_dev_loader, nn.NLLLoss(reduction='sum'))\n",
    "print (\"\\n{} Validation Accuracy = {}\".format(config.val_test_lang.upper(), val_acc))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.6.3"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
