{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 21,
   "metadata": {},
   "outputs": [],
   "source": [
    "import pickle\n",
    "import random\n",
    "import spacy\n",
    "import csv\n",
    "import sys\n",
    "import errno\n",
    "import glob\n",
    "import string\n",
    "import io\n",
    "import os\n",
    "import jieba\n",
    "import re\n",
    "import nltk\n",
    "import time\n",
    "import functools\n",
    "import numpy as np\n",
    "import pandas as pd\n",
    "from setuptools import setup\n",
    "from collections import Counter\n",
    "from collections import defaultdict\n",
    "from argparse import ArgumentParser\n",
    "\n",
    "import torch\n",
    "import torch.nn as nn\n",
    "import torch.optim as optim\n",
    "from torch.optim import lr_scheduler\n",
    "from torch.utils.data import Dataset\n",
    "import torch.nn.functional as F\n",
    "from torch.autograd import Variable\n",
    "\n",
    "import matplotlib.pyplot as plt\n",
    "%matplotlib inline"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "metadata": {},
   "outputs": [],
   "source": [
    "PAD_IDX = 0\n",
    "UNK_IDX = 1\n",
    "label_dict = {\"entailment\":0, \"neutral\":1, \"contradiction\":2}"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "metadata": {},
   "outputs": [],
   "source": [
    "no_cuda = False\n",
    "cuda = not no_cuda and torch.cuda.is_available()\n",
    "seed = 1\n",
    "device = torch.device(\"cuda\" if cuda else \"cpu\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "metadata": {},
   "outputs": [],
   "source": [
    "opus_path = \"/scratch/adc563/nlu_project/data/opus\"\n",
    "europarl_path = \"/scratch/adc563/nlu_project/data/europarl\"\n",
    "un_path = \"/scratch/adc563/nlu_project/data/un_parallel_corpora\""
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "metadata": {},
   "outputs": [],
   "source": [
    "def read_xnli(lang):\n",
    "    fname = \"/scratch/adc563/nlu_project/data/XNLI/xnli.{}.jsonl\"\n",
    "    xnli_dev = pd.read_json(fname.format(\"dev\"), lines=True)\n",
    "    xnli_test = pd.read_json(fname.format(\"test\"), lines=True)\n",
    "    if lang == \"all\":\n",
    "        dev_data = xnli_dev\n",
    "        test_data = xnli_test\n",
    "    else:\n",
    "        dev_data = xnli_dev[xnli_dev[\"language\"]==lang]\n",
    "        test_data = xnli_test[xnli_test[\"language\"]==lang]\n",
    "    return dev_data, test_data\n",
    "\n",
    "def load_aligned_vectors(lang):\n",
    "    f = \"/scratch/adc563/nlu_project/data/aligned_embeddings/wiki.{}.align.vec\".format(lang)\n",
    "    fin = io.open(f, \"r\", encoding=\"utf-8\", newline=\"\\n\", errors=\"ignore\")\n",
    "    n, d = map(int, fin.readline().split())\n",
    "    data = {}\n",
    "    for line in fin:\n",
    "        tokens = line.rstrip().split(\" \")\n",
    "        data[tokens[0]] = [*map(float, tokens[1:])]\n",
    "    return data\n",
    "\n",
    "def load_multilingual_vectors(lang):\n",
    "    fname = \"/scratch/adc563/nlu_project/data/multi_lingual_embeddings/cc.{}.300.vec\".format(lang)\n",
    "    fin = io.open(fname, 'r', encoding='utf-8', newline='\\n', errors='ignore')\n",
    "    n = map(int, fin.readline().split())\n",
    "    data = {}\n",
    "    for line in fin:\n",
    "        tokens = line.rstrip().split(' ')\n",
    "        data[tokens[0]] = map(float, tokens[1:])\n",
    "    return data\n",
    "\n",
    "def load_glove_vectors(lang):\n",
    "    f = \"/scratch/adc563/nlu_project/HBMP/vector_cache/glove.840B.300d.txt\".format(lang)\n",
    "    fin = io.open(f, \"r\", encoding=\"utf-8\", newline=\"\\n\", errors=\"ignore\")\n",
    "    n = map(int, fin.readline().split())\n",
    "    data = {}\n",
    "    for line in fin:\n",
    "        tokens = line.rstrip().split(\" \")\n",
    "        data[tokens[0]] = [*map(float, tokens[1:])]\n",
    "    return data\n",
    "\n",
    "def read_enli(nli_corpus = \"snli\"):\n",
    "    if nli_corpus == \"snli\":\n",
    "        path_ = \"/scratch/adc563/nlu_project/HBMP/data/snli/snli_1.0/snli_1.0\"\n",
    "        train = pd.read_json(\"{}_{}.jsonl\".format(path_,\"train\"), lines=True)\n",
    "        dev = pd.read_json(\"{}_{}.jsonl\".format(path_,\"dev\"), lines=True)\n",
    "        test = pd.read_json(\"{}_{}.jsonl\".format(path_,\"test\"), lines=True)\n",
    "        # remove - from gold label\n",
    "        train = train[train[\"gold_label\"] != \"-\"]\n",
    "        dev = dev[dev[\"gold_label\"] != \"-\"]\n",
    "        test = test[test[\"gold_label\"] != \"-\"]\n",
    "    elif nli_corpus == \"multinli\":\n",
    "        path_ = \"/scratch/adc563/nlu_project/HBMP/data/multinli/multinli_1.0/multinli_1.0\"\n",
    "        train = pd.read_json(\"{}_{}.jsonl\".format(path_,\"train\"), lines=True)\n",
    "        dev = pd.read_json(\"{}_{}_matched.jsonl\".format(path_, \"dev\"), lines=True)\n",
    "        test = None\n",
    "        # remove - from gold label\n",
    "        train = train[train[\"gold_label\"] != \"-\"]\n",
    "        dev = dev[dev[\"gold_label\"] != \"-\"]\n",
    "    return train, dev, test\n",
    "\n",
    "def write_numeric_label(train, dev, test, nli_corpus=\"multinli\"):\n",
    "    if nli_corpus == \"multinli\":\n",
    "        for dataset in [train, dev]:\n",
    "            dataset[\"gold_label\"] = dataset[\"gold_label\"].apply(lambda x: label_dict[x])\n",
    "    elif nli_corpus == \"snli\":\n",
    "        for dataset in [train, dev, test]:\n",
    "            dataset[\"gold_label\"] = dataset[\"gold_label\"].apply(lambda x: label_dict[x])\n",
    "    elif nli_corpus == \"xnli\":\n",
    "        for dataset in [dev, test]:\n",
    "            dataset[\"gold_label\"] = dataset[\"gold_label\"].apply(lambda x: label_dict[x])\n",
    "    else:\n",
    "        raise ValueError (\"NLI corpus name should be in [multinli, snli, xnli]\")\n",
    "    return train, dev, test\n",
    "\n",
    "def tokenize_xnli(dataset, remove_punc=False, lang=\"en\"):\n",
    "    all_s1_tokens = []\n",
    "    all_s2_tokens = []\n",
    "    punc = [*string.punctuation]\n",
    "    if lang == \"ar\":\n",
    "        for s in [\"sentence1\", \"sentence2\"]:\n",
    "            dataset[\"{}_tokenized\".format(s)] = dataset[s].\\\n",
    "            apply(lambda x: [a + \".ar\" for a in nltk.tokenize.wordpunct_tokenize(x)])\n",
    "        ext = dataset[\"sentence1_tokenized\"].apply(lambda x: all_s1_tokens.extend(x))\n",
    "        ext1 = dataset[\"sentence2_tokenized\"].apply(lambda x: all_s2_tokens.extend(x))\n",
    "        all_tokens = all_s1_tokens + all_s2_tokens\n",
    "    elif lang == \"zh\":\n",
    "        for s in [\"sentence1\", \"sentence2\"]:\n",
    "            dataset[\"{}_tokenized\".format(s)] = dataset[s].\\\n",
    "            apply(lambda x: [z + \".zh\" for z in ' '.join(jieba.cut(x, cut_all=True)).split(\" \")])\n",
    "        ext = dataset[\"sentence1_tokenized\"].apply(lambda x: all_s1_tokens.extend(x))\n",
    "        ext1 = dataset[\"sentence2_tokenized\"].apply(lambda x: all_s2_tokens.extend(x))\n",
    "        all_tokens = all_s1_tokens + all_s2_tokens\n",
    "    else:\n",
    "        for s in [\"sentence1\", \"sentence2\"]:\n",
    "            dataset[\"{}_tokenized\".format(s)] = dataset[s].\\\n",
    "            apply(lambda x: \"\".join(c for c in x if c not in string.punctuation).lower().split(\" \"))\n",
    "            dataset[\"{}_tokenized\".format(s)] = dataset[\"{}_tokenized\".format(s)].\\\n",
    "            apply(lambda x: [a+\".\"+lang for a in x])\n",
    "        ext = dataset[\"sentence1_tokenized\"].apply(lambda x: all_s1_tokens.extend(x))\n",
    "        ext1 = dataset[\"sentence2_tokenized\"].apply(lambda x: all_s2_tokens.extend(x))\n",
    "        all_tokens = all_s1_tokens + all_s2_tokens\n",
    "    return dataset, all_tokens\n",
    "\n",
    "\n",
    "\n",
    "def build_vocab(all_tokens, max_vocab_size):\n",
    "    token_counter = Counter(all_tokens)\n",
    "    vocab, count = zip(*token_counter.most_common(max_vocab_size))\n",
    "    id2token = [*vocab]\n",
    "    token2id = dict(zip(vocab, range(2,2+len(vocab))))\n",
    "    id2token = ['<PAD>', '<UNK>'] + id2token\n",
    "    token2id[\"<PAD>\"] = 0\n",
    "    token2id[\"<UNK>\"] = 1\n",
    "    return token2id, id2token\n",
    "\n",
    "def build_tok2id(id2token):\n",
    "    token2id = {}\n",
    "    for i in range(len(id2token)):\n",
    "        token2id[id2token[i]] = i\n",
    "    return token2id\n",
    "\n",
    "def init_embedding_weights(vectors, token2id, id2token, embedding_size):\n",
    "    weights = np.zeros((len(id2token), embedding_size))\n",
    "    for idx in range(2, len(id2token)):\n",
    "        token = id2token[idx]\n",
    "        weights[idx] = vectors[token]\n",
    "    weights[1] = np.random.randn(embedding_size)\n",
    "    return weights"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "metadata": {},
   "outputs": [],
   "source": [
    "class config_class:\n",
    "    def __init__(self, corpus, val_test_lang, max_sent_len, max_vocab_size, epochs, batch_size, \n",
    "                    embed_dim, hidden_dim, dropout, lr, experiment_lang):\n",
    "        self.corpus = corpus\n",
    "        self.val_test_lang = val_test_lang\n",
    "        self.max_sent_len = max_sent_len\n",
    "        self.max_vocab_size = max_vocab_size\n",
    "        self.epochs = epochs\n",
    "        self.batch_size = batch_size\n",
    "        self.embed_dim = embed_dim\n",
    "        self.hidden_dim = hidden_dim\n",
    "        self.dropout = dropout\n",
    "        self.lr = lr\n",
    "        self.experiment_lang = experiment_lang"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 8,
   "metadata": {},
   "outputs": [],
   "source": [
    "config = config_class(corpus = \"multinli\",\n",
    "             val_test_lang = \"zh\",\n",
    "             max_sent_len = 30,\n",
    "             max_vocab_size = 210000,\n",
    "             epochs = 15,\n",
    "             batch_size = 64, \n",
    "             embed_dim = 300,\n",
    "             hidden_dim = 512,\n",
    "             dropout = 0.1,\n",
    "             lr = 1e-3,\n",
    "             experiment_lang = \"zh\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 9,
   "metadata": {},
   "outputs": [],
   "source": [
    "def update_vocab_keys(src_vocab, trg_vocab):\n",
    "    for x in [*src_vocab.keys()]:\n",
    "        src_vocab[x + \".en\"] = src_vocab[x]\n",
    "        src_vocab.pop(x)\n",
    "    for y in [*trg_vocab.keys()]:\n",
    "        trg_vocab[y + \".{}\".format(config.experiment_lang)] = trg_vocab[y]\n",
    "        trg_vocab.pop(y)\n",
    "        \n",
    "    src_vocab.update(trg_vocab)\n",
    "    return src_vocab"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 10,
   "metadata": {
    "scrolled": false
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Loading vectors for EN.\n"
     ]
    }
   ],
   "source": [
    "print (\"Loading vectors for EN.\")\n",
    "aligned_src_vectors = load_glove_vectors(\"en\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 11,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Loading vectors for ZH.\n"
     ]
    }
   ],
   "source": [
    "print (\"Loading vectors for {}.\".format(config.experiment_lang.upper()))\n",
    "aligned_trg_vectors = load_aligned_vectors(config.experiment_lang)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 12,
   "metadata": {},
   "outputs": [],
   "source": [
    "id2token_src = [x+\".\"+\"en\" for x in [*aligned_src_vectors.keys()]][:config.max_vocab_size]\n",
    "id2token_trg = [x+\".\"+config.experiment_lang for x in [*aligned_trg_vectors.keys()]][:config.max_vocab_size]\n",
    "id2token_mutual = [\"<PAD>\", \"<UNK>\"] + id2token_src + id2token_trg\n",
    "vecs_mutual = update_vocab_keys(aligned_src_vectors, aligned_trg_vectors)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 13,
   "metadata": {},
   "outputs": [],
   "source": [
    "def init_embedding_weights(vectors, token2id, id2token, embedding_size):\n",
    "    weights = np.zeros((len(id2token), embedding_size))\n",
    "    for idx in range(2, len(id2token)):\n",
    "        token = id2token[idx]\n",
    "        weights[idx] = vectors[token]\n",
    "    weights[1] = np.random.randn(embedding_size)\n",
    "    return weights"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 14,
   "metadata": {},
   "outputs": [],
   "source": [
    "token2id_mutual = build_tok2id(id2token_mutual)\n",
    "weights_init = init_embedding_weights(vecs_mutual, token2id_mutual, id2token_mutual, 300)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 15,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "420002"
      ]
     },
     "execution_count": 15,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "len(id2token_mutual)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 16,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "(420002, 300)"
      ]
     },
     "execution_count": 16,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "weights_init.shape"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 63,
   "metadata": {},
   "outputs": [],
   "source": [
    "def read_and_tokenize_opus_data(lang=\"tr\"):\n",
    "    all_en_tokens = []\n",
    "    all_target_tokens = []\n",
    "    path_en = opus_path + \"/{}_en/en_data_00\".format(lang, lang)\n",
    "    path_target = opus_path + \"/{}_en/{}_data_00\".format(lang, lang)\n",
    "    en_corpus = open(path_en, \"r\")\n",
    "    target_corpus = open(path_target, \"r\")\n",
    "    en_series = pd.Series(en_corpus.read().split(\"\\n\"))\n",
    "    target_series = pd.Series(target_corpus.read().split(\"\\n\"))\n",
    "    dataset = pd.DataFrame({\"en\":en_series, lang:target_series})\n",
    "    if lang == \"ar\":\n",
    "        dataset[\"en_tokenized\"] = dataset[\"en\"].apply(lambda x: \"\".join(c for c in x if c not in string.punctuation).lower().split(\" \"))\n",
    "        dataset[\"en_tokenized\"] = dataset[\"en_tokenized\"].apply(lambda x:[a+\".en\" for a in x])\n",
    "        dataset[\"ar_tokenized\"] = dataset[\"ar\"].apply(lambda x: [a + \".ar\" for a in nltk.tokenize.wordpunct_tokenize(x)])\n",
    "    elif lang == \"zh\":\n",
    "        dataset[\"en_tokenized\"] = dataset[\"en\"].apply(lambda x: \"\".join(c for c in x if c not in string.punctuation).lower().split(\" \"))\n",
    "        dataset[\"en_tokenized\"] = dataset[\"en_tokenized\"].apply(lambda x:[a+\".en\" for a in x])\n",
    "        dataset[\"zh_tokenized\"] = dataset[\"zh\"].apply(lambda x: [z + \".zh\" for z in ' '.join(jieba.cut(x, cut_all=True)).split(\" \") if z not in string.punctuation])\n",
    "    else:\n",
    "        for i in [\"en\", lang]:\n",
    "            dataset[\"{}_tokenized\".format(i)] = dataset[i].apply(lambda x: \"\".join(c for c in x if c not in string.punctuation).lower().split(\" \"))\n",
    "            dataset[\"{}_tokenized\".format(i)] = dataset[\"{}_tokenized\".format(i)].\\\n",
    "            apply(lambda x:[a+\".{}\".format(i) for a in x])\n",
    "    dataset[\"en_tokenized\"].apply(lambda x: all_en_tokens.extend(x))\n",
    "    dataset[\"{}_tokenized\".format(lang)].apply(lambda x: all_target_tokens.extend(x))\n",
    "    return dataset, all_en_tokens, all_target_tokens"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 61,
   "metadata": {},
   "outputs": [],
   "source": [
    "def read_and_tokenize_europarl_data(lang=\"de\"):\n",
    "    all_en_tok = []\n",
    "    all_target_tok = []\n",
    "    path_en = europarl_path + \"/{}_en/europarl-v7.{}-en.en\".format(lang, lang)\n",
    "    path_target = europarl_path + \"/{}_en/europarl-v7.{}-en.{}\".format(lang, lang, lang)\n",
    "    en_corpus = open(path_en, \"r\")\n",
    "    target_corpus = open(path_target, \"r\")\n",
    "    en_series = pd.Series(en_corpus.read().split(\"\\n\"))\n",
    "    target_series = pd.Series(target_corpus.read().split(\"\\n\"))\n",
    "    dataset = pd.DataFrame({\"en\":en_series, lang:target_series})\n",
    "    for i in [\"en\", lang]:\n",
    "        dataset[\"{}_tokenized\".format(i)] = dataset[i].apply(lambda x: \"\".join(c for c in x if c not in string.punctuation).lower().split(\" \"))\n",
    "        dataset[\"{}_tokenized\".format(i)] = dataset[\"{}_tokenized\".format(i)].apply(lambda x:[a+\".{}\".format(i) for a in x])\n",
    "    dataset[\"en_tokenized\"].apply(lambda x: all_en_tok.extend(x))\n",
    "    dataset[\"{}_tokenized\".format(lang)].apply(lambda x: all_target_tok.extend(x))\n",
    "    return dataset, all_en_tokens, all_target_tokens"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 64,
   "metadata": {},
   "outputs": [],
   "source": [
    "data_en_target, all_en_tokens, all_target_tokens = read_and_tokenize_opus_data(lang=config.val_test_lang)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 65,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>en</th>\n",
       "      <th>zh</th>\n",
       "      <th>en_tokenized</th>\n",
       "      <th>zh_tokenized</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>0</th>\n",
       "      <td>Ah, this is greasy. I want to eat kimchee.</td>\n",
       "      <td>好想要吃泡菜</td>\n",
       "      <td>[ah.en, this.en, is.en, greasy.en, i.en, want....</td>\n",
       "      <td>[好.zh, 想要.zh, 吃.zh, 泡菜.zh]</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1</th>\n",
       "      <td>Is Chae Yoon's coordinator in here?</td>\n",
       "      <td>崔允的造型师在吗</td>\n",
       "      <td>[is.en, chae.en, yoons.en, coordinator.en, in....</td>\n",
       "      <td>[崔.zh, 允.zh, 的.zh, 造型.zh, 造型师.zh, 在.zh, 吗.zh]</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2</th>\n",
       "      <td>Excuse me, aren't you Chae Yoon's coordinator?</td>\n",
       "      <td>请问一下 你是不是崔允的造型师</td>\n",
       "      <td>[excuse.en, me.en, arent.en, you.en, chae.en, ...</td>\n",
       "      <td>[请问.zh, 一下.zh, 你.zh, 是不是.zh, 不是.zh, 崔.zh, 允.zh...</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "</div>"
      ],
      "text/plain": [
       "                                               en               zh  \\\n",
       "0      Ah, this is greasy. I want to eat kimchee.           好想要吃泡菜   \n",
       "1             Is Chae Yoon's coordinator in here?         崔允的造型师在吗   \n",
       "2  Excuse me, aren't you Chae Yoon's coordinator?  请问一下 你是不是崔允的造型师   \n",
       "\n",
       "                                        en_tokenized  \\\n",
       "0  [ah.en, this.en, is.en, greasy.en, i.en, want....   \n",
       "1  [is.en, chae.en, yoons.en, coordinator.en, in....   \n",
       "2  [excuse.en, me.en, arent.en, you.en, chae.en, ...   \n",
       "\n",
       "                                        zh_tokenized  \n",
       "0                         [好.zh, 想要.zh, 吃.zh, 泡菜.zh]  \n",
       "1      [崔.zh, 允.zh, 的.zh, 造型.zh, 造型师.zh, 在.zh, 吗.zh]  \n",
       "2  [请问.zh, 一下.zh, 你.zh, 是不是.zh, 不是.zh, 崔.zh, 允.zh...  "
      ]
     },
     "execution_count": 65,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "data_en_target.head(3)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 100,
   "metadata": {},
   "outputs": [],
   "source": [
    "data_en_target[\"len_en\"] = data_en_target[\"en_tokenized\"].apply(lambda x: len(x))\n",
    "data_en_target[\"len_{}\".format(config.val_test_lang)] = \\\n",
    "data_en_target[\"{}_tokenized\".format(config.val_test_lang)].apply(lambda x: len(x))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 101,
   "metadata": {},
   "outputs": [],
   "source": [
    "data_en_target = data_en_target[(data_en_target[\"len_en\"] > 1)&(data_en_target[\"len_{}\".format(config.val_test_lang)] > 1)]\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 66,
   "metadata": {},
   "outputs": [],
   "source": [
    "def create_contrastive_dataset(dataset, trg_lang):\n",
    "    shuffle_ix_src = torch.randperm(len(dataset))\n",
    "    src_c = np.array([*dataset[\"{}_tokenized\".format(\"en\")].values])[shuffle_ix_src]\n",
    "    trg_c = dataset[\"{}_tokenized\".format(trg_lang)]\n",
    "    contrastive_df = pd.DataFrame({\"en_tokenized\": src_c, \"{}_tokenized\".format(trg_lang): trg_c})\n",
    "    return contrastive_df"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 67,
   "metadata": {},
   "outputs": [],
   "source": [
    "c_df = create_contrastive_dataset(data_en_target, config.val_test_lang)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 68,
   "metadata": {},
   "outputs": [],
   "source": [
    "c_df = c_df.iloc[torch.randperm(len(c_df))]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 69,
   "metadata": {},
   "outputs": [],
   "source": [
    "c_df[\"{}_tokenized\".format(config.experiment_lang)].iloc[:100000] = \\\n",
    "c_df[\"{}_tokenized\".format(config.experiment_lang)].iloc[:100000]\\\n",
    ".apply(lambda x: [np.random.choice(x) for s in range(len(x)-1)])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 70,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>en_tokenized</th>\n",
       "      <th>zh_tokenized</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>599889</th>\n",
       "      <td>[why.en, is.en, it.en, always.en, some.en, fuc...</td>\n",
       "      <td>[對.zh, 扯.zh, 澤.zh, 頭.zh, 他.zh, 澤.zh]</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>127534</th>\n",
       "      <td>[reggie.en, usually.en, yeah.en, yeah.en]</td>\n",
       "      <td>[徜徉.zh, 徜徉.zh, 你.zh, 徜徉.zh]</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1577536</th>\n",
       "      <td>[i.en, gotta.en, cook.en]</td>\n",
       "      <td>[]</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>218596</th>\n",
       "      <td>[they.en, are.en]</td>\n",
       "      <td>[原谅.zh, 可以.zh, 你.zh]</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1301603</th>\n",
       "      <td>[ive.en, touched.en, you.en, so.en, often.en, ...</td>\n",
       "      <td>[号叫.zh, 死者.zh, 号叫.zh, 华.zh, 失血.zh, 烂.zh, 命.zh,...</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "</div>"
      ],
      "text/plain": [
       "                                              en_tokenized  \\\n",
       "599889   [why.en, is.en, it.en, always.en, some.en, fuc...   \n",
       "127534           [reggie.en, usually.en, yeah.en, yeah.en]   \n",
       "1577536                          [i.en, gotta.en, cook.en]   \n",
       "218596                                   [they.en, are.en]   \n",
       "1301603  [ive.en, touched.en, you.en, so.en, often.en, ...   \n",
       "\n",
       "                                              zh_tokenized  \n",
       "599889                [對.zh, 扯.zh, 澤.zh, 頭.zh, 他.zh, 澤.zh]  \n",
       "127534                         [徜徉.zh, 徜徉.zh, 你.zh, 徜徉.zh]  \n",
       "1577536                                                 []  \n",
       "218596                                [原谅.zh, 可以.zh, 你.zh]  \n",
       "1301603  [号叫.zh, 死者.zh, 号叫.zh, 华.zh, 失血.zh, 烂.zh, 命.zh,...  "
      ]
     },
     "execution_count": 70,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "c_df.head()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 71,
   "metadata": {},
   "outputs": [],
   "source": [
    "shuffle_ix = torch.randperm(len(c_df))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 72,
   "metadata": {},
   "outputs": [],
   "source": [
    "c_df[\"{}_tokenized\".format(config.experiment_lang)] = np.array(c_df[\"{}_tokenized\".format(config.experiment_lang)])[shuffle_ix]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 73,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>en_tokenized</th>\n",
       "      <th>zh_tokenized</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>599889</th>\n",
       "      <td>[why.en, is.en, it.en, always.en, some.en, fuc...</td>\n",
       "      <td>[回到.zh, 维多.zh, 维多利.zh, 维多利亚.zh, 多利.zh, 多利亚.zh,...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>127534</th>\n",
       "      <td>[reggie.en, usually.en, yeah.en, yeah.en]</td>\n",
       "      <td>[是因为.zh, 因为.zh, 露.zh, 娜.zh, 你.zh, 对.zh, 她.zh, ...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1577536</th>\n",
       "      <td>[i.en, gotta.en, cook.en]</td>\n",
       "      <td>[看看.zh, 我.zh, 这儿.zh, 有.zh, 多少.zh]</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>218596</th>\n",
       "      <td>[they.en, are.en]</td>\n",
       "      <td>[罗伯特.zh, 雷.zh, 福.zh]</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1301603</th>\n",
       "      <td>[ive.en, touched.en, you.en, so.en, often.en, ...</td>\n",
       "      <td>[今天.zh, 早上.zh, 7.zh, 点.zh, 我.zh, 看见.zh, 他.zh, ...</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "</div>"
      ],
      "text/plain": [
       "                                              en_tokenized  \\\n",
       "599889   [why.en, is.en, it.en, always.en, some.en, fuc...   \n",
       "127534           [reggie.en, usually.en, yeah.en, yeah.en]   \n",
       "1577536                          [i.en, gotta.en, cook.en]   \n",
       "218596                                   [they.en, are.en]   \n",
       "1301603  [ive.en, touched.en, you.en, so.en, often.en, ...   \n",
       "\n",
       "                                              zh_tokenized  \n",
       "599889   [回到.zh, 维多.zh, 维多利.zh, 维多利亚.zh, 多利.zh, 多利亚.zh,...  \n",
       "127534   [是因为.zh, 因为.zh, 露.zh, 娜.zh, 你.zh, 对.zh, 她.zh, ...  \n",
       "1577536                  [看看.zh, 我.zh, 这儿.zh, 有.zh, 多少.zh]  \n",
       "218596                                [罗伯特.zh, 雷.zh, 福.zh]  \n",
       "1301603  [今天.zh, 早上.zh, 7.zh, 点.zh, 我.zh, 看见.zh, 他.zh, ...  "
      ]
     },
     "execution_count": 73,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "c_df.head()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 74,
   "metadata": {},
   "outputs": [],
   "source": [
    "c_df[\"len_en\"] = c_df[\"en_tokenized\"].apply(lambda x: len(x))\n",
    "c_df[\"len_{}\".format(config.val_test_lang)] = \\\n",
    "c_df[\"{}_tokenized\".format(config.val_test_lang)].apply(lambda x: len(x))\n",
    "\n",
    "c_df = c_df[(c_df[\"len_en\"] > 1)&(c_df[\"len_{}\".format(config.val_test_lang)] > 1)]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 79,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>en_tokenized</th>\n",
       "      <th>zh_tokenized</th>\n",
       "      <th>len_en</th>\n",
       "      <th>len_zh</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>599889</th>\n",
       "      <td>[why.en, is.en, it.en, always.en, some.en, fuc...</td>\n",
       "      <td>[回到.zh, 维多.zh, 维多利.zh, 维多利亚.zh, 多利.zh, 多利亚.zh,...</td>\n",
       "      <td>9</td>\n",
       "      <td>8</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>127534</th>\n",
       "      <td>[reggie.en, usually.en, yeah.en, yeah.en]</td>\n",
       "      <td>[是因为.zh, 因为.zh, 露.zh, 娜.zh, 你.zh, 对.zh, 她.zh, ...</td>\n",
       "      <td>4</td>\n",
       "      <td>11</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1577536</th>\n",
       "      <td>[i.en, gotta.en, cook.en]</td>\n",
       "      <td>[看看.zh, 我.zh, 这儿.zh, 有.zh, 多少.zh]</td>\n",
       "      <td>3</td>\n",
       "      <td>5</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>218596</th>\n",
       "      <td>[they.en, are.en]</td>\n",
       "      <td>[罗伯特.zh, 雷.zh, 福.zh]</td>\n",
       "      <td>2</td>\n",
       "      <td>3</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1301603</th>\n",
       "      <td>[ive.en, touched.en, you.en, so.en, often.en, ...</td>\n",
       "      <td>[今天.zh, 早上.zh, 7.zh, 点.zh, 我.zh, 看见.zh, 他.zh, ...</td>\n",
       "      <td>11</td>\n",
       "      <td>15</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "</div>"
      ],
      "text/plain": [
       "                                              en_tokenized  \\\n",
       "599889   [why.en, is.en, it.en, always.en, some.en, fuc...   \n",
       "127534           [reggie.en, usually.en, yeah.en, yeah.en]   \n",
       "1577536                          [i.en, gotta.en, cook.en]   \n",
       "218596                                   [they.en, are.en]   \n",
       "1301603  [ive.en, touched.en, you.en, so.en, often.en, ...   \n",
       "\n",
       "                                              zh_tokenized  len_en  len_zh  \n",
       "599889   [回到.zh, 维多.zh, 维多利.zh, 维多利亚.zh, 多利.zh, 多利亚.zh,...       9       8  \n",
       "127534   [是因为.zh, 因为.zh, 露.zh, 娜.zh, 你.zh, 对.zh, 她.zh, ...       4      11  \n",
       "1577536                  [看看.zh, 我.zh, 这儿.zh, 有.zh, 多少.zh]       3       5  \n",
       "218596                                [罗伯特.zh, 雷.zh, 福.zh]       2       3  \n",
       "1301603  [今天.zh, 早上.zh, 7.zh, 点.zh, 我.zh, 看见.zh, 他.zh, ...      11      15  "
      ]
     },
     "execution_count": 79,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "c_df.head()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 102,
   "metadata": {},
   "outputs": [],
   "source": [
    "class AlignDataset(Dataset):\n",
    "    def __init__(self, data, max_sent_len, src_lang, trg_lang,\n",
    "                 token2id, id2token):\n",
    "        self.src = [*data[\"{}_tokenized\".format(src_lang)].values]\n",
    "        self.trg = [*data[\"{}_tokenized\".format(trg_lang)].values]\n",
    "        self.max_sent_len = int(max_sent_len)\n",
    "        self.token2id, self.id2token = token2id, id2token\n",
    "        \n",
    "    def __len__(self):\n",
    "        return len(self.src)\n",
    "    \n",
    "    def __getitem__(self, row):\n",
    "        src_ix, trg_ix = [], []\n",
    "        src_mask, trg_mask = [], []\n",
    "        for w in self.src[row][:self.max_sent_len]:\n",
    "            if w in self.token2id.keys():\n",
    "                src_ix.append(self.token2id[w])\n",
    "                src_mask.append(0)\n",
    "            else:\n",
    "                src_ix.append(UNK_IDX)\n",
    "                src_mask.append(1)\n",
    "        for w in self.trg[row][:self.max_sent_len]:\n",
    "            if w in self.token2id.keys():\n",
    "                trg_ix.append(self.token2id[w])\n",
    "                trg_mask.append(0)\n",
    "            else:\n",
    "                trg_ix.append(UNK_IDX)\n",
    "                trg_mask.append(1)\n",
    "        \n",
    "        src_list = [src_ix, src_mask, len(src_ix)]\n",
    "        trg_list = [trg_ix, trg_mask, len(trg_mask)]\n",
    "        return src_list + trg_list\n",
    "    \n",
    "def align_collate_func(batch, max_sent_len):\n",
    "    src_data, trg_data = [], []\n",
    "    src_mask, trg_mask = [], []\n",
    "    src_len, trg_len = [], []\n",
    "    \n",
    "    for datum in batch:\n",
    "        src_len.append(datum[2])\n",
    "        trg_len.append(datum[5])\n",
    "        src_data_padded = np.pad(np.array(datum[0]), pad_width=((0, max_sent_len-datum[2])), mode=\"constant\", constant_values=PAD_IDX)\n",
    "        src_data.append(src_data_padded)\n",
    "        src_mask_padded = np.pad(np.array(datum[1]), pad_width=((0, max_sent_len-datum[2])), mode=\"constant\", constant_values=PAD_IDX)\n",
    "        src_mask.append(src_mask_padded)\n",
    "        trg_data_padded = np.pad(np.array(datum[3]), pad_width=((0, max_sent_len-datum[5])), mode=\"constant\", constant_values=PAD_IDX)\n",
    "        trg_data.append(trg_data_padded)\n",
    "        trg_mask_padded = np.pad(np.array(datum[4]), pad_width=((0, max_sent_len-datum[5])), mode=\"constant\", constant_values=PAD_IDX)\n",
    "        trg_mask.append(trg_mask_padded)\n",
    "        \n",
    "    ind_dec_order = np.argsort(src_len)[::-1]\n",
    "    src_data = np.array(src_data)[ind_dec_order]\n",
    "    trg_data = np.array(trg_data)[ind_dec_order]\n",
    "    src_mask = np.array(src_mask)[ind_dec_order].reshape(len(batch), -1, 1)\n",
    "    trg_mask = np.array(trg_mask)[ind_dec_order].reshape(len(batch), -1, 1)\n",
    "    src_len = np.array(src_len)[ind_dec_order]\n",
    "    trg_len = np.array(trg_len)[ind_dec_order]\n",
    "\n",
    "    return [torch.from_numpy(src_data), torch.from_numpy(src_mask).float(), src_len,\n",
    "            torch.from_numpy(trg_data), torch.from_numpy(trg_mask).float(), trg_len]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 103,
   "metadata": {},
   "outputs": [],
   "source": [
    "# her epochta kaydet\n",
    "align_dataset = AlignDataset(data_en_target, config.max_sent_len, \"en\", config.experiment_lang,\n",
    "                             token2id_mutual, id2token_mutual)\n",
    "align_loader = torch.utils.data.DataLoader(dataset=align_dataset, batch_size=config.batch_size,\n",
    "                               collate_fn=lambda x, max_sentence_length=config.max_sent_len: align_collate_func(x, config.max_sent_len),\n",
    "                               shuffle=False)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 104,
   "metadata": {},
   "outputs": [],
   "source": [
    "c_align_dataset = AlignDataset(c_df, config.max_sent_len, \"en\", config.experiment_lang, \n",
    "                               token2id_mutual, id2token_mutual)\n",
    "c_align_loader = torch.utils.data.DataLoader(dataset=c_align_dataset, batch_size=config.batch_size,\n",
    "                               collate_fn=lambda x, max_sentence_length=config.max_sent_len: align_collate_func(x, config.max_sent_len),\n",
    "                               shuffle=False)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 105,
   "metadata": {},
   "outputs": [],
   "source": [
    "def loss_align(en_rep, target_rep, en_c, target_c, lambda_reg):\n",
    "    \"\"\":param en_rep: output repr of eng encoder (batch_size, hidden_size)\n",
    "       :param target_rep: output repr of target encoder (batch_size, hidden_size)\n",
    "       :param en_c: contrastive sentence repr from eng encoder (batch_size, hidden_size)\n",
    "       :param target_c: contrastive sentence repr form target encoder (batch_size, hidden_size)\n",
    "       :param lambda_reg: regularization coef [default: 0.25]\n",
    "\n",
    "    Returns: L_align = l2norm (en_rep, target_rep) - lambda_reg( l2norm (en_c, target_rep) + l2norm (en_rep, target_c))\n",
    "    \"\"\"\n",
    "    dist = torch.norm(en_rep - target_rep, 2)\n",
    "    c_dist = torch.norm(en_c - target_rep, 2) + torch.norm(en_rep - target_c, 2)\n",
    "    L_align = dist - lambda_reg*(c_dist)\n",
    "    return L_align"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 106,
   "metadata": {},
   "outputs": [],
   "source": [
    "def loss_align(en_rep, target_rep, en_c, target_c, lambda_reg):\n",
    "    \"\"\":param en_rep: output repr of eng encoder (batch_size, hidden_size)\n",
    "       :param target_rep: output repr of target encoder (batch_size, hidden_size)\n",
    "       :param en_c: contrastive sentence repr from eng encoder (batch_size, hidden_size)\n",
    "       :param target_c: contrastive sentence repr form target encoder (batch_size, hidden_size)\n",
    "       :param lambda_reg: regularization coef [default: 0.25]\n",
    "\n",
    "    Returns: L_align = l2norm (en_rep, target_rep) - lambda_reg( l2norm (en_c, target_rep) + l2norm (en_rep, target_c))\n",
    "    \"\"\"\n",
    "    dist = torch.norm(en_rep - target_rep, 2)\n",
    "    c_dist = torch.norm(en_c - target_rep, 2) + torch.norm(en_rep - target_c, 2)\n",
    "    L_align = dist - lambda_reg*(c_dist)\n",
    "    return L_align"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 107,
   "metadata": {},
   "outputs": [],
   "source": [
    "class biLSTM(nn.Module):\n",
    "    \n",
    "    def __init__(self,\n",
    "                 hidden_size,\n",
    "                 embedding_weights,\n",
    "                 percent_dropout,\n",
    "                 vocab_size,\n",
    "                 interaction_type=\"concat\",\n",
    "                 num_layers=1,\n",
    "                 input_size=300,\n",
    "                 src_trg = \"src\"):\n",
    "\n",
    "        super(biLSTM, self).__init__()\n",
    "        \n",
    "        self.num_layers, self.hidden_size = num_layers, hidden_size\n",
    "        \n",
    "        self.embed_table = torch.from_numpy(embedding_weights).float()\n",
    "        embedding = nn.Embedding.from_pretrained(self.embed_table)\n",
    "\n",
    "        self.embedding = embedding\n",
    "        self.interaction = interaction_type\n",
    "        self.dropout = percent_dropout\n",
    "        self.drop_out = nn.Dropout(self.dropout)\n",
    "        \n",
    "        self.LSTM = nn.LSTM(300, hidden_size, num_layers, batch_first=True, bidirectional=True)\n",
    "        if self.LSTM.bidirectional:\n",
    "            self.num_directions = 2\n",
    "        else:\n",
    "            self.num_directions = 1\n",
    "            \n",
    "        self.bn = nn.BatchNorm1d(self.hidden_size * self.num_directions)\n",
    "        \n",
    "    def init_hidden(self, batch_size):\n",
    "        hidden = torch.randn(self.num_directions*self.num_layers, batch_size, self.hidden_size).to(device)\n",
    "        c_0 = torch.randn(self.num_directions*self.num_layers, batch_size, self.hidden_size).to(device)\n",
    "        return hidden, c_0\n",
    "    \n",
    "    def forward(self, sentence, mask, lengths):\n",
    "        sort_original = sorted(range(len(lengths)), key=lambda sentence: -lengths[sentence])\n",
    "        unsort_to_original = sorted(range(len(lengths)), key=lambda sentence: sort_original[sentence])\n",
    "        \n",
    "        sentence = sentence[sort_original]\n",
    "        _mask = mask[sort_original]\n",
    "        lengths = lengths[sort_original]\n",
    "        batch_size, seq_len = sentence.size()\n",
    "        self.hidden, self.c_0 = self.init_hidden(batch_size)\n",
    "        \n",
    "        # embdddings\n",
    "        embeds = self.embedding(sentence)\n",
    "        embeds = mask*embeds + (1-_mask)*embeds.clone().detach()\n",
    "        embeds = torch.nn.utils.rnn.pack_padded_sequence(embeds, lengths, batch_first=True)\n",
    "        # first lstm\n",
    "        lstm_out, (self.hidden_1, self.c_1) = self.LSTM(embeds, (self.hidden, self.c_0))\n",
    "        emb1, _ = torch.nn.utils.rnn.pad_packed_sequence(lstm_out, batch_first=True)\n",
    "        \n",
    "        emb1 = emb1.view(batch_size, -1, 2, self.hidden_size)\n",
    "        emb1 = torch.max(emb1, dim=1)[0]\n",
    "        emb1 = torch.cat([emb1[:,i,:] for i in range(self.num_directions)], dim=1)\n",
    "        emb1 = emb1[unsort_to_original]\n",
    "        \n",
    "        out = self.bn(emb1)\n",
    "        \n",
    "        return out"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 108,
   "metadata": {},
   "outputs": [],
   "source": [
    "class Discriminator(nn.Module):\n",
    "\n",
    "    def __init__(self, n_langs, dis_layers, dis_hidden_dim, dis_dropout):\n",
    "\n",
    "        super(Discriminator, self).__init__()\n",
    "        self.n_langs = n_langs\n",
    "        self.input_dim = config.hidden_dim * self.n_langs\n",
    "        self.dis_layers = dis_layers\n",
    "        self.dis_hidden_dim = dis_hidden_dim\n",
    "        self.dis_dropout = dis_dropout\n",
    "\n",
    "        layers = []\n",
    "        for i in range(self.dis_layers + 1):\n",
    "            if i == 0:\n",
    "                input_dim = self.input_dim\n",
    "            else:\n",
    "                input_dim = self.dis_hidden_dim\n",
    "            output_dim = self.dis_hidden_dim if i < self.dis_layers else self.n_langs\n",
    "            layers.append(nn.Linear(input_dim, output_dim))\n",
    "            if i < self.dis_layers:\n",
    "                layers.append(nn.LeakyReLU(0.28))\n",
    "                layers.append(nn.Dropout(self.dis_dropout))\n",
    "        self.layers = nn.Sequential(*layers)\n",
    "\n",
    "    def forward(self, input):\n",
    "        out = self.layers(input)\n",
    "        out = F.log_softmax(out, 1)\n",
    "        return out"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": 109,
   "metadata": {},
   "outputs": [],
   "source": [
    "# src: always English\n",
    "def train(LSTM_src, LSTM_trg, discriminator, loader, contrastive_loader, optimizer, dis_optim, epoch):\n",
    "    LSTM_src.train()\n",
    "    LSTM_trg.train()\n",
    "    discriminator.train()\n",
    "    total_loss = 0\n",
    "    for batch_idx, ([src_data, src_mask, src_len, trg_data, trg_mask, trg_len],\n",
    "                    [src_c, src_mc, src_len_c, trg_c, trg_mc, trg_len_c]) in \\\n",
    "        enumerate(zip(loader, contrastive_loader)):\n",
    "        \n",
    "        src_data, src_mask = src_data.to(device), src_mask.to(device)\n",
    "        trg_data, trg_mask = trg_data.to(device), trg_mask.to(device)\n",
    "        src_c, src_mc = src_c.to(device), src_mc.to(device)\n",
    "        trg_c, trg_mc = trg_c.to(device), trg_mc.to(device)\n",
    "        optimizer.zero_grad()\n",
    "        dis_optim.zero_grad()\n",
    "        if np.random.random() <= 0.02:\n",
    "            src_data = src_data + torch.rand(src_data.size()).long().to(device)\n",
    "            trg_data = trg_data + torch.rand(trg_data.size()).long().to(device)\n",
    "#             src_c = src_c + torch.rand(src_c.size()).long().to(device)\n",
    "#             trg_c = trg_c + torch.rand(trg_c.size()).long().to(device)\n",
    "            \n",
    "        src_out = LSTM_src(src_data, src_mask, src_len)\n",
    "        trg_out = LSTM_trg(trg_data, trg_mask, trg_len)\n",
    "        src_c_out = LSTM_src(src_c, src_mc, src_len_c)\n",
    "        trg_c_out = LSTM_trg(trg_c, trg_mc, trg_len_c)\n",
    "        loss = loss_align(src_out, trg_out, src_c_out, trg_c_out, 0.25)\n",
    "        loss.cuda().backward(retain_graph=True)\n",
    "        # step\n",
    "        optimizer.step()\n",
    "        total_loss += loss.item() * len(src_data) / len(loader.dataset)\n",
    "        if (batch_idx+1) % (len(loader.dataset)//(50*config.batch_size)) == 0:\n",
    "            \n",
    "            dis_labels_src = torch.zeros(config.batch_size).long()\n",
    "            dis_labels_trg = torch.ones(config.batch_size).long()\n",
    "            dis_labels = torch.cat([dis_labels_src, dis_labels_trg], 0)\n",
    "            idx = torch.randperm(config.batch_size * 2)\n",
    "            dis_input = torch.cat([src_out, trg_out], 0)\n",
    "            dis_input = dis_input[idx]\n",
    "            dis_labels = dis_labels[idx].to(device)\n",
    "            dis_out = discriminator(dis_input)\n",
    "            dis_criterion = nn.NLLLoss()\n",
    "            dis_loss = dis_criterion(dis_out, dis_labels)\n",
    "            dis_loss.cuda().backward(retain_graph=True)\n",
    "            dis_optim.step()\n",
    "            \n",
    "            loss += (-1) * dis_criterion(dis_out, dis_labels)\n",
    "            loss.cuda().backward()\n",
    "            optimizer.step()\n",
    "            \n",
    "            torch.save(LSTM_trg.state_dict(), \"LSTM_en_{}_{}_epoch_{}\".format(config.experiment_lang,\n",
    "                                                                      config.experiment_lang.upper(),\n",
    "                                                                      epoch))\n",
    "            \n",
    "            print('Train Epoch: {} [{}/{} ({:.0f}%)]\\tLoss: {:.4f}'.format(\n",
    "                epoch, (batch_idx+1) * config.batch_size, len(loader.dataset),\n",
    "                100. * (batch_idx+1) / len(loader), loss.item()))\n",
    "            \n",
    "    optimizer.zero_grad()\n",
    "    return total_loss"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 110,
   "metadata": {
    "scrolled": false
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Encoder src:\n",
      " biLSTM(\n",
      "  (embedding): Embedding(420002, 300)\n",
      "  (drop_out): Dropout(p=0.1)\n",
      "  (LSTM): LSTM(300, 512, batch_first=True, bidirectional=True)\n",
      "  (bn): BatchNorm1d(1024, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)\n",
      ")\n",
      "Encoder trg:\n",
      " biLSTM(\n",
      "  (embedding): Embedding(420002, 300)\n",
      "  (drop_out): Dropout(p=0.1)\n",
      "  (LSTM): LSTM(300, 512, batch_first=True, bidirectional=True)\n",
      "  (bn): BatchNorm1d(1024, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)\n",
      ")\n",
      "Discriminator:\n",
      " Discriminator(\n",
      "  (layers): Sequential(\n",
      "    (0): Linear(in_features=1024, out_features=128, bias=True)\n",
      "    (1): LeakyReLU(negative_slope=0.28)\n",
      "    (2): Dropout(p=0.1)\n",
      "    (3): Linear(in_features=128, out_features=128, bias=True)\n",
      "    (4): LeakyReLU(negative_slope=0.28)\n",
      "    (5): Dropout(p=0.1)\n",
      "    (6): Linear(in_features=128, out_features=128, bias=True)\n",
      "    (7): LeakyReLU(negative_slope=0.28)\n",
      "    (8): Dropout(p=0.1)\n",
      "    (9): Linear(in_features=128, out_features=128, bias=True)\n",
      "    (10): LeakyReLU(negative_slope=0.28)\n",
      "    (11): Dropout(p=0.1)\n",
      "    (12): Linear(in_features=128, out_features=128, bias=True)\n",
      "    (13): LeakyReLU(negative_slope=0.28)\n",
      "    (14): Dropout(p=0.1)\n",
      "    (15): Linear(in_features=128, out_features=2, bias=True)\n",
      "  )\n",
      ")\n",
      "\n",
      "epoch = 0\n",
      "Train Epoch: 0 [36160/1809550 (2%)]\tLoss: 46.2443\n",
      "Train Epoch: 0 [72320/1809550 (4%)]\tLoss: 39.0146\n",
      "Train Epoch: 0 [108480/1809550 (6%)]\tLoss: 38.3323\n",
      "Train Epoch: 0 [144640/1809550 (8%)]\tLoss: 40.3817\n",
      "Train Epoch: 0 [180800/1809550 (10%)]\tLoss: 34.6209\n",
      "Train Epoch: 0 [216960/1809550 (12%)]\tLoss: 35.8538\n",
      "Train Epoch: 0 [253120/1809550 (14%)]\tLoss: 39.5464\n",
      "Train Epoch: 0 [289280/1809550 (16%)]\tLoss: 48.9710\n",
      "Train Epoch: 0 [325440/1809550 (18%)]\tLoss: 33.4963\n",
      "Train Epoch: 0 [361600/1809550 (20%)]\tLoss: 30.9756\n",
      "Train Epoch: 0 [397760/1809550 (22%)]\tLoss: 32.4718\n",
      "Train Epoch: 0 [433920/1809550 (24%)]\tLoss: 34.2086\n",
      "Train Epoch: 0 [470080/1809550 (26%)]\tLoss: 36.3662\n",
      "Train Epoch: 0 [506240/1809550 (28%)]\tLoss: 31.8469\n",
      "Train Epoch: 0 [542400/1809550 (30%)]\tLoss: 34.3894\n",
      "Train Epoch: 0 [578560/1809550 (32%)]\tLoss: 36.9495\n",
      "Train Epoch: 0 [614720/1809550 (34%)]\tLoss: 35.7353\n",
      "Train Epoch: 0 [650880/1809550 (36%)]\tLoss: 30.1327\n",
      "Train Epoch: 0 [687040/1809550 (38%)]\tLoss: 27.7652\n",
      "Train Epoch: 0 [723200/1809550 (40%)]\tLoss: 35.7831\n",
      "Train Epoch: 0 [759360/1809550 (42%)]\tLoss: 34.3974\n",
      "Train Epoch: 0 [795520/1809550 (44%)]\tLoss: 35.7999\n",
      "Train Epoch: 0 [831680/1809550 (46%)]\tLoss: 27.4993\n",
      "Train Epoch: 0 [867840/1809550 (48%)]\tLoss: 38.0732\n",
      "Train Epoch: 0 [904000/1809550 (50%)]\tLoss: 27.1976\n",
      "Train Epoch: 0 [940160/1809550 (52%)]\tLoss: 28.7675\n",
      "Train Epoch: 0 [976320/1809550 (54%)]\tLoss: 30.7835\n",
      "Train Epoch: 0 [1012480/1809550 (56%)]\tLoss: 39.4647\n",
      "Train Epoch: 0 [1048640/1809550 (58%)]\tLoss: 40.5085\n",
      "Train Epoch: 0 [1084800/1809550 (60%)]\tLoss: 43.5232\n",
      "Train Epoch: 0 [1120960/1809550 (62%)]\tLoss: 32.2414\n",
      "Train Epoch: 0 [1157120/1809550 (64%)]\tLoss: 38.5189\n",
      "Train Epoch: 0 [1193280/1809550 (66%)]\tLoss: 37.2685\n",
      "Train Epoch: 0 [1229440/1809550 (68%)]\tLoss: 25.5846\n",
      "Train Epoch: 0 [1265600/1809550 (70%)]\tLoss: 33.1261\n",
      "Train Epoch: 0 [1301760/1809550 (72%)]\tLoss: 26.6693\n",
      "Train Epoch: 0 [1337920/1809550 (74%)]\tLoss: 41.8106\n",
      "Train Epoch: 0 [1374080/1809550 (76%)]\tLoss: 34.2342\n",
      "Train Epoch: 0 [1410240/1809550 (78%)]\tLoss: 36.3494\n",
      "Train Epoch: 0 [1446400/1809550 (80%)]\tLoss: 31.9409\n",
      "Train Epoch: 0 [1482560/1809550 (82%)]\tLoss: 32.6881\n",
      "Train Epoch: 0 [1518720/1809550 (84%)]\tLoss: 35.8233\n",
      "Train Epoch: 0 [1554880/1809550 (86%)]\tLoss: 32.6455\n",
      "Train Epoch: 0 [1591040/1809550 (88%)]\tLoss: 33.1924\n",
      "Train Epoch: 0 [1627200/1809550 (90%)]\tLoss: 32.8967\n",
      "Train Epoch: 0 [1663360/1809550 (92%)]\tLoss: 35.2225\n",
      "Train Epoch: 0 [1699520/1809550 (94%)]\tLoss: 31.7110\n",
      "Train Epoch: 0 [1735680/1809550 (96%)]\tLoss: 31.8453\n"
     ]
    },
    {
     "ename": "RuntimeError",
     "evalue": "The size of tensor a (43) must match the size of tensor b (64) at non-singleton dimension 0",
     "output_type": "error",
     "traceback": [
      "\u001b[0;31m---------------------------------------------------------------------------\u001b[0m",
      "\u001b[0;31mRuntimeError\u001b[0m                              Traceback (most recent call last)",
      "\u001b[0;32m<ipython-input-110-cec10e96046d>\u001b[0m in \u001b[0;36m<module>\u001b[0;34m\u001b[0m\n\u001b[1;32m     27\u001b[0m                        dis_optim = torch.optim.Adam([*disc.parameters()],\n\u001b[1;32m     28\u001b[0m                                                     lr=config.lr), \n\u001b[0;32m---> 29\u001b[0;31m                        epoch = epoch)\n\u001b[0m\u001b[1;32m     30\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m     31\u001b[0m     torch.save(LSTM_trg_model.state_dict(), \"LSTM_en_{}_{}_epoch_{}\".format(config.experiment_lang,\n",
      "\u001b[0;32m<ipython-input-109-a452f5f36115>\u001b[0m in \u001b[0;36mtrain\u001b[0;34m(LSTM_src, LSTM_trg, discriminator, loader, contrastive_loader, optimizer, dis_optim, epoch)\u001b[0m\n\u001b[1;32m     25\u001b[0m         \u001b[0msrc_c_out\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mLSTM_src\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0msrc_c\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0msrc_mc\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0msrc_len_c\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m     26\u001b[0m         \u001b[0mtrg_c_out\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mLSTM_trg\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mtrg_c\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mtrg_mc\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mtrg_len_c\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m---> 27\u001b[0;31m         \u001b[0mloss\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mloss_align\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0msrc_out\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mtrg_out\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0msrc_c_out\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mtrg_c_out\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0;36m0.25\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m     28\u001b[0m         \u001b[0mloss\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mcuda\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mbackward\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mretain_graph\u001b[0m\u001b[0;34m=\u001b[0m\u001b[0;32mTrue\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m     29\u001b[0m         \u001b[0;31m# step\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n",
      "\u001b[0;32m<ipython-input-106-320b45ff9497>\u001b[0m in \u001b[0;36mloss_align\u001b[0;34m(en_rep, target_rep, en_c, target_c, lambda_reg)\u001b[0m\n\u001b[1;32m      9\u001b[0m     \"\"\"\n\u001b[1;32m     10\u001b[0m     \u001b[0mdist\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mtorch\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mnorm\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0men_rep\u001b[0m \u001b[0;34m-\u001b[0m \u001b[0mtarget_rep\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0;36m2\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m---> 11\u001b[0;31m     \u001b[0mc_dist\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mtorch\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mnorm\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0men_c\u001b[0m \u001b[0;34m-\u001b[0m \u001b[0mtarget_rep\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0;36m2\u001b[0m\u001b[0;34m)\u001b[0m \u001b[0;34m+\u001b[0m \u001b[0mtorch\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mnorm\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0men_rep\u001b[0m \u001b[0;34m-\u001b[0m \u001b[0mtarget_c\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0;36m2\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m     12\u001b[0m     \u001b[0mL_align\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mdist\u001b[0m \u001b[0;34m-\u001b[0m \u001b[0mlambda_reg\u001b[0m\u001b[0;34m*\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mc_dist\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m     13\u001b[0m     \u001b[0;32mreturn\u001b[0m \u001b[0mL_align\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n",
      "\u001b[0;31mRuntimeError\u001b[0m: The size of tensor a (43) must match the size of tensor b (64) at non-singleton dimension 0"
     ]
    }
   ],
   "source": [
    "load_epoch = 3\n",
    "LSTM_src_model = biLSTM(hidden_size=config.hidden_dim, embedding_weights=weights_init ,num_layers=1, percent_dropout = config.dropout, \n",
    "             vocab_size=weights_init.shape[0], interaction_type=\"concat\", input_size=300).to(device)\n",
    "LSTM_src_model.load_state_dict(torch.load(\"best_encoder_eng_mnli_{}_{}\".format(load_epoch, \n",
    "                                                                        config.experiment_lang)))\n",
    "for param in LSTM_src_model.parameters():\n",
    "    param.requires_grad = False\n",
    "\n",
    "LSTM_trg_model = biLSTM(hidden_size=config.hidden_dim, embedding_weights=weights_init ,num_layers=1, percent_dropout = config.dropout, \n",
    "             vocab_size=weights_init.shape[0], interaction_type=\"concat\", input_size=300).to(device)\n",
    "LSTM_trg_model.load_state_dict(torch.load(\"best_encoder_eng_mnli_{}_{}\".format(load_epoch, \n",
    "                                                                        config.experiment_lang)))\n",
    "\n",
    "disc = Discriminator(n_langs = 2, dis_layers = 5, dis_hidden_dim = 128, dis_dropout = 0.1).to(device)\n",
    "\n",
    "print (\"Encoder src:\\n\", LSTM_src_model)\n",
    "print (\"Encoder trg:\\n\", LSTM_trg_model)\n",
    "print (\"Discriminator:\\n\", disc)\n",
    "\n",
    "for epoch in range(config.epochs):\n",
    "    print (\"\\nepoch = \"+str(epoch))\n",
    "    \n",
    "    loss_train = train(LSTM_src=LSTM_src_model, LSTM_trg=LSTM_trg_model, discriminator = disc,\n",
    "                       loader=align_loader, contrastive_loader=c_align_loader,\n",
    "                       optimizer = torch.optim.Adam([*LSTM_src_model.parameters()] + [*LSTM_trg_model.parameters()] + [*disc.parameters()],\n",
    "                                                    lr=config.lr), \n",
    "                       dis_optim = torch.optim.Adam([*disc.parameters()],\n",
    "                                                    lr=config.lr), \n",
    "                       epoch = epoch)\n",
    "\n",
    "    torch.save(LSTM_trg_model.state_dict(), \"LSTM_en_{}_{}_epoch_{}\".format(config.experiment_lang,\n",
    "                                                                      config.experiment_lang.upper(),\n",
    "                                                                      epoch))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# minus NLL_loss?"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# NOW: new kind of contrastiveness "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.6.3"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
